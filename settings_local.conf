# Logging Configuration
# ----------------------------------------
logger=zerolog

logLevel=INFO
logLevel.dev=DEBUG
logLevel.docker=DEBUG

logger_output_format=| %-25s| %-7s| %s |

logger_show_timestamps=true
logger_show_socket_info=true


http_timeout=1000
http_sign_response=true

# Ports Configuration
# ----------------------------------------
ASSET_GRPC_PORT=8091
ASSET_HTTP_PORT=8090
BLOCK_ASSEMBLY_GRPC_PORT=8085
BLOCK_VALIDATION_GRPC_PORT=8088
BLOCK_VALIDATION_HTTP_PORT=8188
SUBTREE_VALIDATION_GRPC_PORT=8086
BLOCKCHAIN_GRPC_PORT=8087
BLOCKCHAIN_HTTP_PORT=8082
BOOTSTRAP_GRPC_PORT=8089
BOOTSTRAP_HTTP_PORT=8099
COINBASE_GRPC_PORT=8093
FAUCET_HTTP_PORT=8097
JAEGER_PORT=6831
MINER_HTTP_PORT=8092
P2P_BOOTSTRAP_PORT=9901
P2P_HTTP_PORT=9906
P2P_PORT=9905
P2P_PORT_COINBASE=9907
PROFILE_PORT=9091
PROFILE_PORT_TXBLASTER=9092
PROPAGATION_GRPC_PORT=8084
PROPAGATION_HTTP_PORT=8833
PROPAGATION_QUIC_PORT=8384
REDIS_PORT=6379
VALIDATOR_GRPC_PORT=8081
CENTRIFUGE_PORT=8892
LEGACY_HTTP_PORT=8098

# Core Stats Configuration
# ----------------------------------------
gocore_stats_reported_time_threshold=24h
stats_prefix=gocore

# Profiler Configuration
# ----------------------------------------
profilerAddr=:${PROFILE_PORT}
profilerAddr.dev=localhost:${PROFILE_PORT}
profilerAddr.docker.host.ubsv1=localhost:1${PROFILE_PORT}
profilerAddr.docker.host.ubsv2=localhost:2${PROFILE_PORT}
profilerAddr.docker.host.ubsv3=localhost:3${PROFILE_PORT}


# Security Configuration
# ----------------------------------------
securityLevelHTTP=0
securityLevelGRPC=0

server_certFile=certs/ubsv.crt
server_keyFile=certs/ubsv.key

# Aerospike read/write policy defaults
# ----------------------------------------
aerospike_debug=false
aerospike_useDefaultBasePolicies=false
aerospike_useDefaultPolicies=false
aerospike_warmUp=true

# The following 3 policies are used for all read/write operations when the aerospike_useDefaultPolicies is false
# SleepBetweenRetries is not being used in the current implementation
# SleepMultiplier is not being used in the current implementation
# ExitFastOnExhaustedConnectionPool is not being used in the current implementation
aerospike_batchPolicy=aerospike:///?MaxRetries=5&SleepBetweenRetries=500ms&SleepMultiplier=1&TotalTimeout=64s&SocketTimeout=10s&ConcurrentNodes=0
aerospike_readPolicy=aerospike:///?MaxRetries=5&SleepBetweenRetries=500ms&SleepMultiplier=1&TotalTimeout=1s&SocketTimeout=1s
aerospike_writePolicy=aerospike:///?MaxRetries=5&SleepBetweenRetries=500ms&SleepMultiplier=1&TotalTimeout=1s&SocketTimeout=1s


# Prometheus and Tracing Configuration
# ----------------------------------------
prometheusEndpoint=/metrics

use_open_tracing=false

tracing_SampleRate=0.01

# careful! this variable only works for tminer-lo-1he OTEL tracer. If you're using open tracing you need to set JAEGER_AGENT_HOST
tracing_collector_url=jaeger://jaeger-cluster-agent.jaeger.svc.cluster.local:${JAEGER_PORT}
tracing_collector_url.dev=jaeger://:${JAEGER_PORT}
tracing_collector_url.testing.t1=jaeger://jaeger-agent.jaeger.svc.cluster.local:${JAEGER_PORT}
tracing_collector_url.testing.t2=jaeger://jaeger-agent.jaeger.svc.cluster.local:${JAEGER_PORT}
tracing_collector_url.testing.t3=jaeger://jaeger-agent.jaeger.svc.cluster.local:${JAEGER_PORT}



# Advertising Configuration
# ----------------------------------------
advertisingURL=
advertisingInterval=10s


# Grpc Resolver Configuration
# ----------------------------------------
grpc_resolver=dns
grpc_resolver.scaling=k8s

k8s_resolver_ttl=10
k8s_resolver_ttl.dev=0


# Kafka Configuration
# ----------------------------------------
KAFKA_PORT=9092
KAFKA_PORT.dev.kafkatool=9094
KAFKA_PORT.docker.host=19092

KAFKA_HOSTS.dev             = 127.0.0.1:${KAFKA_PORT}
KAFKA_HOSTS.dev.liam        = localhost:${KAFKA_PORT}
KAFKA_HOSTS.docker          = kafka-shared:${KAFKA_PORT}
KAFKA_HOSTS.docker.host     = localhost:${KAFKA_PORT}
KAFKA_HOSTS.scaling.m1      = b-1.ubsvmskeu.4h864p.c3.kafka.eu-west-1.amazonaws.com:${KAFKA_PORT},b-2.ubsvmskeu.4h864p.c3.kafka.eu-west-1.amazonaws.com:${KAFKA_PORT},b-3.ubsvmskeu.4h864p.c3.kafka.eu-west-1.amazonaws.com:${KAFKA_PORT}
KAFKA_HOSTS.scaling.m2      = b-2.ubsvmskus.deer9v.c24.kafka.us-east-1.amazonaws.com:${KAFKA_PORT},b-3.ubsvmskus.deer9v.c24.kafka.us-east-1.amazonaws.com:${KAFKA_PORT},b-1.ubsvmskus.deer9v.c24.kafka.us-east-1.amazonaws.com:${KAFKA_PORT}
KAFKA_HOSTS.scaling.m3      = b-1.ubsvmskasia.o871j9.c3.kafka.ap-south-1.amazonaws.com:${KAFKA_PORT},b-2.ubsvmskasia.o871j9.c3.kafka.ap-south-1.amazonaws.com:${KAFKA_PORT},b-3.ubsvmskasia.o871j9.c3.kafka.ap-south-1.amazonaws.com:${KAFKA_PORT}
KAFKA_HOSTS.scaling.m4      = b-1.ubsvmskane.sz9taz.c3.kafka.ap-northeast-2.amazonaws.com:${KAFKA_PORT},b-2.ubsvmskane.sz9taz.c3.kafka.ap-northeast-2.amazonaws.com:${KAFKA_PORT},b-3.ubsvmskane.sz9taz.c3.kafka.ap-northeast-2.amazonaws.com:${KAFKA_PORT}
KAFKA_HOSTS.scaling.m5      = b-3.ubsvmskcan.f2xt8x.c3.kafka.ca-central-1.amazonaws.com:${KAFKA_PORT},b-1.ubsvmskcan.f2xt8x.c3.kafka.ca-central-1.amazonaws.com:${KAFKA_PORT},b-2.ubsvmskcan.f2xt8x.c3.kafka.ca-central-1.amazonaws.com:${KAFKA_PORT}
KAFKA_HOSTS.scaling.m6      = b-1.ubsvmskusw.gmnud6.c4.kafka.us-west-2.amazonaws.com:${KAFKA_PORT},b-2.ubsvmskusw.gmnud6.c4.kafka.us-west-2.amazonaws.com:${KAFKA_PORT},b-3.ubsvmskusw.gmnud6.c4.kafka.us-west-2.amazonaws.com:${KAFKA_PORT}

# use the same kafka cluster for the testing env
KAFKA_HOSTS.testing.t1      = b-1.ubsvmskeuc.hnkv05.c6.kafka.eu-central-1.amazonaws.com:${KAFKA_PORT},b-2.ubsvmskeuc.hnkv05.c6.kafka.eu-central-1.amazonaws.com:${KAFKA_PORT},b-3.ubsvmskeuc.hnkv05.c6.kafka.eu-central-1.amazonaws.com:${KAFKA_PORT}
KAFKA_HOSTS.testing.t2      = b-1.ubsvmskeuc.hnkv05.c6.kafka.eu-central-1.amazonaws.com:${KAFKA_PORT},b-2.ubsvmskeuc.hnkv05.c6.kafka.eu-central-1.amazonaws.com:${KAFKA_PORT},b-3.ubsvmskeuc.hnkv05.c6.kafka.eu-central-1.amazonaws.com:${KAFKA_PORT}
KAFKA_HOSTS.testing.t3      = b-1.ubsvmskeuc.hnkv05.c6.kafka.eu-central-1.amazonaws.com:${KAFKA_PORT},b-2.ubsvmskeuc.hnkv05.c6.kafka.eu-central-1.amazonaws.com:${KAFKA_PORT},b-3.ubsvmskeuc.hnkv05.c6.kafka.eu-central-1.amazonaws.com:${KAFKA_PORT}

KAFKA_HOSTS.docker.ci.ubsv3.debug          = 127.0.0.1:${KAFKA_PORT}

KAFKA_REPLICATION_FACTOR=1
KAFKA_REPLICATION_FACTOR.scaling=3

KAFKA_PARTITIONS=1
KAFKA_PARTITIONS.scaling=768

KAFKA_BLOCKS=blocks
KAFKA_BLOCKS.docker.ci.ubsv1=blocks1
KAFKA_BLOCKS.docker.ci.ubsv2=blocks2
KAFKA_BLOCKS.docker.ci.ubsv3=blocks3
KAFKA_BLOCKS.docker.host.ubsv1=blocks12
KAFKA_BLOCKS.docker.host.ubsv2=blocks2
KAFKA_BLOCKS.docker.host.ubsv3=blocks3
KAFKA_BLOCKS_VALIDATE=blocks-validate
KAFKA_SUBTREES=subtrees
KAFKA_SUBTREES.docker.ci.ubsv1=subtrees1
KAFKA_SUBTREES.docker.ci.ubsv2=subtrees2
KAFKA_SUBTREES.docker.ci.ubsv3=subtrees3
KAFKA_SUBTREES.docker.host.ubsv1=subtrees1
KAFKA_SUBTREES.docker.host.ubsv2=subtrees2
KAFKA_SUBTREES.docker.host.ubsv3=subtrees3
KAFKA_TXS=txs
KAFKA_TXS.docker.ci.ubsv1=txs1
KAFKA_TXS.docker.ci.ubsv2=txs2
KAFKA_TXS.docker.ci.ubsv3=txs3
KAFKA_TXS.docker.host.ubsv1=txs1
KAFKA_TXS.docker.host.ubsv2=txs2
KAFKA_TXS.docker.host.ubsv3=txs3
KAFKA_TXMETA=txmeta
KAFKA_TXMETA.docker.ci.ubsv1=txmeta1
KAFKA_TXMETA.docker.ci.ubsv2=txmeta2
KAFKA_TXMETA.docker.ci.ubsv3=txmeta3
KAFKA_TXMETA.docker.host.ubsv1=txmeta1
KAFKA_TXMETA.docker.host.ubsv2=txmeta2
KAFKA_TXMETA.docker.host.ubsv3=txmeta3
KAFKA_SUBTREES_FINAL=subtrees-final
KAFKA_SUBTREES_FINAL.docker.ci.ubsv1=subtrees-final1
KAFKA_SUBTREES_FINAL.docker.ci.ubsv2=subtrees-final2
KAFKA_SUBTREES_FINAL.docker.ci.ubsv3=subtrees-final3
KAFKA_SUBTREES_FINAL.docker.host.ubsv1=subtrees-final1
KAFKA_SUBTREES_FINAL.docker.host.ubsv2=subtrees-final2
KAFKA_SUBTREES_FINAL.docker.host.ubsv3=subtrees-final3
KAFKA_BLOCKS_FINAL=blocks-final
KAFKA_BLOCKS_FINAL.docker.ci.ubsv1=blocks-final1
KAFKA_BLOCKS_FINAL.docker.ci.ubsv2=blocks-final2
KAFKA_BLOCKS_FINAL.docker.ci.ubsv3=blocks-final3
KAFKA_BLOCKS_FINAL.docker.host.ubsv1=blocks-final1
KAFKA_BLOCKS_FINAL.docker.host.ubsv2=blocks-final2
KAFKA_BLOCKS_FINAL.docker.host.ubsv3=blocks-final3

kafka_blocksConfig                    = kafka://${KAFKA_HOSTS}/${KAFKA_BLOCKS}?partitions=${KAFKA_PARTITIONS}&replication=${KAFKA_REPLICATION_FACTOR}&flush_bytes=64
kafka_blocksConfig.dev.simon          = kafka://${KAFKA_HOSTS}/${KAFKA_BLOCKS}?partitions=${KAFKA_PARTITIONS}&replication=${KAFKA_REPLICATION_FACTOR}&flush_bytes=64
kafka_blocksConfig.dev.legacy         =
kafka_blocksConfig.scaling            = kafka://${KAFKA_HOSTS}/${KAFKA_BLOCKS}?partitions=${KAFKA_PARTITIONS}&replication=${KAFKA_REPLICATION_FACTOR}&flush_bytes=64
kafka_blocksConfig.testing.t1         = kafka://${KAFKA_HOSTS}/${KAFKA_BLOCKS}-t1?partitions=1&replication=3&flush_bytes=64
kafka_blocksConfig.testing.t2         = kafka://${KAFKA_HOSTS}/${KAFKA_BLOCKS}-t2?partitions=1&replication=3&flush_bytes=64
kafka_blocksConfig.testing.t3         = kafka://${KAFKA_HOSTS}/${KAFKA_BLOCKS}-t3?partitions=1&replication=3&flush_bytes=64

# a separate topic for the block validation service to signal to validate a block
kafka_blocksValidateConfig            = kafka://${KAFKA_HOSTS}/${KAFKA_BLOCKS_VALIDATE}?partitions=${KAFKA_PARTITIONS}&replication=${KAFKA_REPLICATION_FACTOR}&flush_bytes=64
kafka_blocksValidateConfig.dev.simon  = kafka://${KAFKA_HOSTS}/${KAFKA_BLOCKS_VALIDATE}?partitions=${KAFKA_PARTITIONS}&replication=${KAFKA_REPLICATION_FACTOR}&flush_bytes=64
kafka_blocksValidateConfig.dev.legacy =
kafka_blocksValidateConfig.scaling    = kafka://${KAFKA_HOSTS}/${KAFKA_BLOCKS_VALIDATE}?partitions=${KAFKA_PARTITIONS}&replication=${KAFKA_REPLICATION_FACTOR}&flush_bytes=64
kafka_blocksValidateConfig.testing.t1    = kafka://${KAFKA_HOSTS}/${KAFKA_BLOCKS_VALIDATE}-t1?partitions=1&replication=3&flush_bytes=64
kafka_blocksValidateConfig.testing.t2    = kafka://${KAFKA_HOSTS}/${KAFKA_BLOCKS_VALIDATE}-t2?partitions=1&replication=3&flush_bytes=64
kafka_blocksValidateConfig.testing.t3    = kafka://${KAFKA_HOSTS}/${KAFKA_BLOCKS_VALIDATE}-t3?partitions=1&replication=3&flush_bytes=64

kafka_blocksFinalConfig               = kafka://${KAFKA_HOSTS}/${KAFKA_BLOCKS_FINAL}?partitions=${KAFKA_PARTITIONS}&replication=${KAFKA_REPLICATION_FACTOR}&flush_bytes=64&autocommit=0
kafka_blocksFinalConfig.dev.simon     = kafka://${KAFKA_HOSTS}/${KAFKA_BLOCKS_FINAL}?partitions=${KAFKA_PARTITIONS}&replication=${KAFKA_REPLICATION_FACTOR}&flush_bytes=64&replay=1&autocommit=0
kafka_blocksFinalConfig.dev.legacy    =
kafka_blocksFinalConfig.scaling       = kafka://${KAFKA_HOSTS}/${KAFKA_BLOCKS_FINAL}?partitions=${KAFKA_PARTITIONS}&replication=${KAFKA_REPLICATION_FACTOR}&flush_bytes=64&replay=1&autocommit=0
kafka_blocksFinalConfig.testing.t1       = kafka://${KAFKA_HOSTS}/${KAFKA_BLOCKS_FINAL}-t1?partitions=1&replication=3&flush_bytes=64&replay=1&autocommit=0
kafka_blocksFinalConfig.testing.t2       = kafka://${KAFKA_HOSTS}/${KAFKA_BLOCKS_FINAL}-t2?partitions=1&replication=3&flush_bytes=64&replay=1&autocommit=0
kafka_blocksFinalConfig.testing.t3       = kafka://${KAFKA_HOSTS}/${KAFKA_BLOCKS_FINAL}-t3?partitions=1&replication=3&flush_bytes=64&replay=1&autocommit=0

kafka_subtreesConfig                  = kafka://${KAFKA_HOSTS}/${KAFKA_SUBTREES}?partitions=${KAFKA_PARTITIONS}&replication=${KAFKA_REPLICATION_FACTOR}&retention=60000&segment_bytes=33554432&flush_bytes=64&flush_messages=1&consumer_ratio=1
kafka_subtreesConfig.dev.simon        = kafka://${KAFKA_HOSTS}/${KAFKA_SUBTREES}?partitions=${KAFKA_PARTITIONS}&replication=${KAFKA_REPLICATION_FACTOR}&retention=60000&flush_bytes=64&flush_messages=1&consumer_ratio=1
kafka_subtreesConfig.dev.legacy       =
kafka_subtreesConfig.scaling          = kafka://${KAFKA_HOSTS}/${KAFKA_SUBTREES}?partitions=${KAFKA_PARTITIONS}&replication=${KAFKA_REPLICATION_FACTOR}&retention=60000&segment_bytes=33554432&flush_bytes=64&flush_messages=1&consumer_ratio=1
kafka_subtreesConfig.testing.t1          = kafka://${KAFKA_HOSTS}/${KAFKA_SUBTREES}-t1?partitions=1&replication=3&retention=60000&segment_bytes=33554432&flush_bytes=64&flush_messages=1&consumer_ratio=1
kafka_subtreesConfig.testing.t2         = kafka://${KAFKA_HOSTS}/${KAFKA_SUBTREES}-t2?partitions=1&replication=3&retention=60000&segment_bytes=33554432&flush_bytes=64&flush_messages=1&consumer_ratio=1
kafka_subtreesConfig.testing.t3          = kafka://${KAFKA_HOSTS}/${KAFKA_SUBTREES}-t3?partitions=1&replication=3&retention=60000&segment_bytes=33554432&flush_bytes=64&flush_messages=1&consumer_ratio=1

kafka_subtreesFinalConfig             = kafka://${KAFKA_HOSTS}/${KAFKA_SUBTREES_FINAL}?partitions=${KAFKA_PARTITIONS}&replication=${KAFKA_REPLICATION_FACTOR}&retention=60000&flush_bytes=64&flush_messages=1
kafka_subtreesFinalConfig.dev.simon   = kafka://${KAFKA_HOSTS}/${KAFKA_SUBTREES_FINAL}?partitions=${KAFKA_PARTITIONS}&replication=${KAFKA_REPLICATION_FACTOR}&retention=60000&flush_bytes=64&flush_messages=1
kafka_subtreesFinalConfig.dev.legacy  =
kafka_subtreesFinalConfig.scaling     = kafka://${KAFKA_HOSTS}/${KAFKA_SUBTREES_FINAL}?partitions=${KAFKA_PARTITIONS}&replication=${KAFKA_REPLICATION_FACTOR}&retention=60000&flush_bytes=64&flush_messages=1
kafka_subtreesFinalConfig.testing.t1     = kafka://${KAFKA_HOSTS}/${KAFKA_SUBTREES_FINAL}-t1?partitions=1&replication=3&retention=60000&flush_bytes=64&flush_messages=1
kafka_subtreesFinalConfig.testing.t2     = kafka://${KAFKA_HOSTS}/${KAFKA_SUBTREES_FINAL}-t2?partitions=1&replication=3&retention=60000&flush_bytes=64&flush_messages=1
kafka_subtreesFinalConfig.testing.t3     = kafka://${KAFKA_HOSTS}/${KAFKA_SUBTREES_FINAL}-t3?partitions=1&replication=3&retention=60000&flush_bytes=64&flush_messages=1

kafka_txsConfig                       = kafka://${KAFKA_HOSTS}/${KAFKA_TXS}?partitions=${KAFKA_PARTITIONS}&replication=${KAFKA_REPLICATION_FACTOR}&retention=60000&flush_bytes=1024&flush_messages=10000&flush_frequency=1s
kafka_txsConfig.scaling               = kafka://${KAFKA_HOSTS}/${KAFKA_TXS}?partitions=${KAFKA_PARTITIONS}&replication=${KAFKA_REPLICATION_FACTOR}&retention=60000&flush_bytes=8192

kafka_txmetaConfig                    = kafka://${KAFKA_HOSTS}/${KAFKA_TXMETA}?partitions=${KAFKA_PARTITIONS}&replication=${KAFKA_REPLICATION_FACTOR}&retention=60000&flush_bytes=1024&flush_messages=10000&flush_frequency=1s&consumer_ratio=4
kafka_txmetaConfig.dev.simon          = kafka://${KAFKA_HOSTS}/${KAFKA_TXMETA}?partitions=${KAFKA_PARTITIONS}&replication=${KAFKA_REPLICATION_FACTOR}&retention=60000&flush_bytes=1024&flush_messages=10000&flush_frequency=1s&consumer_ratio=4
kafka_txmetaConfig.dev.legacy         =
kafka_txmetaConfig.scaling            = kafka://${KAFKA_HOSTS}/${KAFKA_TXMETA}?partitions=${KAFKA_PARTITIONS}&replication=${KAFKA_REPLICATION_FACTOR}&retention=60000&flush_bytes=1024&flush_messages=10000&flush_frequency=1s&consumer_ratio=4
kafka_txmetaConfig.testing.t1            = kafka://${KAFKA_HOSTS}/${KAFKA_TXMETA}-t1?partitions=768&replication=3&retention=60000&flush_bytes=1024&flush_messages=10000&flush_frequency=1s&consumer_ratio=4
kafka_txmetaConfig.testing.t2           = kafka://${KAFKA_HOSTS}/${KAFKA_TXMETA}-t2?partitions=768&replication=3&retention=60000&flush_bytes=1024&flush_messages=10000&flush_frequency=1s&consumer_ratio=4
kafka_txmetaConfig.testing.t3            = kafka://${KAFKA_HOSTS}/${KAFKA_TXMETA}-t3?partitions=768&replication=3&retention=60000&flush_bytes=1024&flush_messages=10000&flush_frequency=1s&consumer_ratio=4


# Propagation Service Configuration
# ----------------------------------------
startPropagation=true
startPropagation.scaling=false
startPropagation.docker.ci.ubsv1.blockassemblyTest=false
startPropagation.docker.ci.ubsv2.blockassemblyTest=false
startPropagation.docker.ci.ubsv3.blockassemblyTest=false

# set this to 0 to disable the propagation client from sending transactions to the propagation service in batches
propagation_sendBatchSize=100
propagation_sendBatchTimeout=10

propagation_grpcListenAddress=:${PROPAGATION_GRPC_PORT}
propagation_grpcListenAddress.dev=localhost:${PROPAGATION_GRPC_PORT}
propagation_grpcListenAddress.docker.host.ubsv1=localhost:1${PROPAGATION_GRPC_PORT}
propagation_grpcListenAddress.docker.host.ubsv2=localhost:2${PROPAGATION_GRPC_PORT}
propagation_grpcListenAddress.docker.host.ubsv3=localhost:3${PROPAGATION_GRPC_PORT}

propagation_grpcMaxConnectionAge=30s
propagation_grpcMaxConnectionAge.scaling=5m

propagation_quicListenAddress=:${PROPAGATION_QUIC_PORT}
propagation_quicListenAddress.dev=localhost:${PROPAGATION_QUIC_PORT}
propagation_quicListenAddress.docker.host.ubsv1=localhost:1${PROPAGATION_QUIC_PORT}
propagation_quicListenAddress.docker.host.ubsv2=localhost:2${PROPAGATION_QUIC_PORT}
propagation_quicListenAddress.docker.host.ubsv3=localhost:3${PROPAGATION_QUIC_PORT}

# Note the following settings can be a pipe separated list
propagation_quicAddresses=https://localhost:${PROPAGATION_QUIC_PORT}
propagation_quicAddresses.docker=
# propagation_quicAddresses.docker=http://ubsv-1:${PROPAGATION_QUIC_PORT}|http://ubsv-2:${PROPAGATION_QUIC_PORT}|http://ubsv-3:${PROPAGATION_QUIC_PORT}
propagation_quicAddresses.scaling=https://m1.scaling.ubsv.dev:${PROPAGATION_QUIC_PORT}|https://m2.scaling.ubsv.dev:${PROPAGATION_QUIC_PORT}

# Note the following settings can be a pipe separated list
propagation_grpcAddresses=localhost:${PROPAGATION_GRPC_PORT}
propagation_grpcAddresses.docker=ubsv-1:${PROPAGATION_GRPC_PORT}|ubsv-2:${PROPAGATION_GRPC_PORT}|ubsv-3:${PROPAGATION_GRPC_PORT}
propagation_grpcAddresses.docker.host=localhost:1${PROPAGATION_GRPC_PORT}|localhost:2${PROPAGATION_GRPC_PORT}|localhost:3${PROPAGATION_GRPC_PORT}
propagation_grpcAddresses.docker.ci.ubsv1.debug=ubsv-1:${PROPAGATION_GRPC_PORT}|ubsv-2:${PROPAGATION_GRPC_PORT}|localhost:${PROPAGATION_GRPC_PORT}
propagation_grpcAddresses.docker.ci.ubsv2.debug=ubsv-1:${PROPAGATION_GRPC_PORT}|ubsv-2:${PROPAGATION_GRPC_PORT}|localhost:${PROPAGATION_GRPC_PORT}
propagation_grpcAddresses.docker.ci.ubsv3.debug=ubsv-1:${PROPAGATION_GRPC_PORT}|ubsv-2:${PROPAGATION_GRPC_PORT}|localhost:${PROPAGATION_GRPC_PORT}
propagation_grpcAddresses.docker.ci.externaltxblaster.ubsv1=localhost:1${PROPAGATION_GRPC_PORT}
propagation_grpcAddresses.docker.ci.externaltxblaster.ubsv2=localhost:2${PROPAGATION_GRPC_PORT}
propagation_grpcAddresses.docker.ci.externaltxblaster.ubsv3=localhost:3${PROPAGATION_GRPC_PORT}
propagation_grpcAddresses.docker.ci.tc1.run=localhost:1${PROPAGATION_GRPC_PORT}|localhost:2${PROPAGATION_GRPC_PORT}|localhost:3${PROPAGATION_GRPC_PORT}

propagation_grpcAddresses.allinone.miner.EU.1=miner-eu-1.miner-eu-1.svc.cluster.local:${PROPAGATION_GRPC_PORT}
propagation_grpcAddresses.allinone.miner.US.1=miner-us-1.miner-us-1.svc.cluster.local:${PROPAGATION_GRPC_PORT}
propagation_grpcAddresses.allinone.miner.AP.1=miner-ap-1.miner-ap-1.svc.cluster.local:${PROPAGATION_GRPC_PORT}
propagation_grpcAddress.docker.ci.ubsv1=ubsv-1:${PROPAGATION_GRPC_PORT}
propagation_grpcAddress.docker.ci.ubsv2=ubsv-2:${PROPAGATION_GRPC_PORT}
propagation_grpcAddress.docker.ci.ubsv3=ubsv-3:${PROPAGATION_GRPC_PORT}
# 2 nodes
# propagation_grpcAddresses.scaling.m1=k8s:///propagation-service1.m1.svc.cluster.local:${PROPAGATION_GRPC_PORT}|dns:///m2.scaling.ubsv.dev:${PROPAGATION_GRPC_PORT}
# propagation_grpcAddresses.scaling.m2=k8s:///propagation-service2.m2.svc.cluster.local:${PROPAGATION_GRPC_PORT}|dns:///m1.scaling.ubsv.dev:${PROPAGATION_GRPC_PORT}

# 3 nodes
# propagation_grpcAddresses.scaling.m1=k8s:///propagation-service1.m1.svc.cluster.local:${PROPAGATION_GRPC_PORT}|dns:///m2.scaling.ubsv.dev:${PROPAGATION_GRPC_PORT}|dns:///m3.scaling.ubsv.dev:${PROPAGATION_GRPC_PORT}
# propagation_grpcAddresses.scaling.m2=k8s:///propagation-service2.m2.svc.cluster.local:${PROPAGATION_GRPC_PORT}|dns:///m1.scaling.ubsv.dev:${PROPAGATION_GRPC_PORT}|dns:///m3.scaling.ubsv.dev:${PROPAGATION_GRPC_PORT}
# propagation_grpcAddresses.scaling.m3=k8s:///propagation-service3.m3.svc.cluster.local:${PROPAGATION_GRPC_PORT}|dns:///m1.scaling.ubsv.dev:${PROPAGATION_GRPC_PORT}|dns:///m2.scaling.ubsv.dev:${PROPAGATION_GRPC_PORT}

M1=dns:///m1.scaling.ubsv.dev:${PROPAGATION_GRPC_PORT}
M2=dns:///m2.scaling.ubsv.dev:${PROPAGATION_GRPC_PORT}
M3=dns:///m3.scaling.ubsv.dev:${PROPAGATION_GRPC_PORT}
M4=dns:///m4.scaling.ubsv.dev:${PROPAGATION_GRPC_PORT}
M5=dns:///m5.scaling.ubsv.dev:${PROPAGATION_GRPC_PORT}
M6=dns:///m6.scaling.ubsv.dev:${PROPAGATION_GRPC_PORT}
T1=dns:///t1.testing.ubsv.dev:${PROPAGATION_GRPC_PORT}
T2=dns:///t2.testing.ubsv.dev:${PROPAGATION_GRPC_PORT}
T3=dns:///t3.testing.ubsv.dev:${PROPAGATION_GRPC_PORT}

# 6 nodes
propagation_grpcAddresses.scaling.m1=k8s:///propagation-service1.m1.svc.cluster.local:${PROPAGATION_GRPC_PORT}|${M2}|${M3}|${M4}|${M5}|${M6}
propagation_grpcAddresses.scaling.m2=k8s:///propagation-service2.m2.svc.cluster.local:${PROPAGATION_GRPC_PORT}|${M1}|${M3}|${M4}|${M5}|${M6}
propagation_grpcAddresses.scaling.m3=k8s:///propagation-service3.m3.svc.cluster.local:${PROPAGATION_GRPC_PORT}|${M1}|${M2}|${M4}|${M5}|${M6}
propagation_grpcAddresses.scaling.m4=k8s:///propagation-service4.m4.svc.cluster.local:${PROPAGATION_GRPC_PORT}|${M1}|${M2}|${M3}|${M5}|${M6}
propagation_grpcAddresses.scaling.m5=k8s:///propagation-service5.m5.svc.cluster.local:${PROPAGATION_GRPC_PORT}|${M1}|${M2}|${M3}|${M4}|${M6}
propagation_grpcAddresses.scaling.m6=k8s:///propagation-service6.m6.svc.cluster.local:${PROPAGATION_GRPC_PORT}|${M1}|${M2}|${M3}|${M4}|${M5}
propagation_grpcAddresses.testing.t1=k8s:///propagation-service-t1.t1.svc.cluster.local:${PROPAGATION_GRPC_PORT}|${T2}|${T3}
propagation_grpcAddresses.testing.t2=k8s:///propagation-service-t2.t2.svc.cluster.local:${PROPAGATION_GRPC_PORT}|${T1}|${T3}
propagation_grpcAddresses.testing.t3=k8s:///propagation-service-t3.t3.svc.cluster.local:${PROPAGATION_GRPC_PORT}|${T1}|${T2}

propagation_httpListenAddress=:${PROPAGATION_HTTP_PORT}
propagation_httpListenAddress.dev=localhost:${PROPAGATION_HTTP_PORT}
propagation_httpListenAddress.docker.host.ubsv1=localhost:1${PROPAGATION_HTTP_PORT}
propagation_httpListenAddress.docker.host.ubsv2=localhost:2${PROPAGATION_HTTP_PORT}
propagation_httpListenAddress.docker.host.ubsv3=localhost:3${PROPAGATION_HTTP_PORT}

propagation_httpAddresses=http://localhost:${PROPAGATION_HTTP_PORT}
propagation_httpAddresses.docker.ci.ubsv1=http://ubsv-1:${PROPAGATION_HTTP_PORT}
propagation_httpAddresses.docker.ci.ubsv2=http://ubsv-2:${PROPAGATION_HTTP_PORT}
propagation_httpAddresses.docker.ci.ubsv3=http://ubsv-3:${PROPAGATION_HTTP_PORT}
propagation_httpAddresses.docker.ci.ubsv3.debug=http://localhost:${PROPAGATION_HTTP_PORT}
propagation_httpAddresses.docker.host.ubsv1=http://localhost:1${PROPAGATION_HTTP_PORT}
propagation_httpAddresses.docker.host.ubsv2=http://localhost:2${PROPAGATION_HTTP_PORT}
propagation_httpAddresses.docker.host.ubsv3=http://localhost:3${PROPAGATION_HTTP_PORT}
propagation_httpAddresses.scaling.m1=http://propagation-service1.m1.svc.cluster.local:${PROPAGATION_HTTP_PORT}
propagation_httpAddresses.scaling.m2=http://propagation-service2.m2.svc.cluster.local:${PROPAGATION_HTTP_PORT}
propagation_httpAddresses.scaling.m3=http://propagation-service3.m3.svc.cluster.local:${PROPAGATION_HTTP_PORT}
propagation_httpAddresses.scaling.m4=http://propagation-service4.m4.svc.cluster.local:${PROPAGATION_HTTP_PORT}
propagation_httpAddresses.scaling.m5=http://propagation-service5.m5.svc.cluster.local:${PROPAGATION_HTTP_PORT}
propagation_httpAddresses.scaling.m6=http://propagation-service6.m6.svc.cluster.local:${PROPAGATION_HTTP_PORT}
propagation_httpAddresses.testing.t1=http://propagation-service-t1.t1.svc.cluster.local:${PROPAGATION_HTTP_PORT}
propagation_httpAddresses.testing.t2=http://propagation-service-t2.t2.svc.cluster.local:${PROPAGATION_HTTP_PORT}
propagation_httpAddresses.testing.t3=http://propagation-service-t3.t3.svc.cluster.local:${PROPAGATION_HTTP_PORT}

txstore=null:///
# txstore=badger:///data/txstore
# use a batcher by passing batch=true in the query parameters
# txstore=file:///data/txstore?batch=true&writeKeys=true
# txstore.docker=file:///data/txstore
# txstore.scaling.m1=s3://s3.eu-west-1.amazonaws.com/eu-ubsv-txstore?region=eu-west-1&batch=true&writeKeys=true&sizeInBytes=33554432
# txstore.scaling.m2=s3://s3.us-east-1.amazonaws.com/us-ubsv-txstore?region=us-east-1&batch=true&writeKeys=true&sizeInBytes=33554432
# txstore.scaling.m3=s3://s3.ap-south-1.amazonaws.com/ap-ubsv-txstore?region=ap-south-1&batch=true&writeKeys=true&sizeInBytes=33554432

txstore.scaling.m1.chainintegrity=null:///

# tx store is processed by the block assembly service
txstore.scaling=null:///

# txstore.scaling.m1=lustre://s3.eu-west-1.amazonaws.com/eu-ubsv-subtree-store?region=eu-west-1&localDir=/data/txstore&localPersist=s3&batch=true&writeKeys=true&sizeInBytes=33554432
# txstore.scaling.m2=lustre://s3.us-east-1.amazonaws.com/us-ubsv-subtree-store?region=us-east-1&localDir=/data/txstore&localPersist=s3&batch=true&writeKeys=true&sizeInBytes=33554432
# txstore.scaling.m3=lustre://s3.ap-south-1.amazonaws.com/ap-ubsv-subtree-store?region=ap-south-1&localDir=/data/txstore&localPersist=s3&batch=true&writeKeys=true&sizeInBytes=33554432

subtreestore                                = badger:///data/subtreestore?localTTLStore=file&localTTLStorePath=data/subtreestore-ttl-1|data/subtreestore-ttl-2
subtreestore.dev                            = null:///?localTTLStore=file&localTTLStorePath=./data/subtreestore-ttl
subtreestore.dev.simon                      = file:///data/subtreestore
subtreestore.docker                         = file:///data/subtreestore
subtreestore.docker.host.ubsv1              = file:///data/ubsv1/subtreestore
subtreestore.docker.host.ubsv2              = file:///data/ubsv2/subtreestore
subtreestore.docker.host.ubsv3              = file:///data/ubsv3/subtreestore
subtreestore.allinone                       = null:///?localTTLStore=file&localTTLStorePath=/data/subtreestore-ttl
subtreestore.allinone.miner.EU              = s3:///eu-ubsv-subtree-store?region=eu-west-1&localTTLStore=file&localTTLStorePath=/data/subtreestore-ttl
subtreestore.allinone.miner.US              = s3:///us-ubsv-subtree-store?region=us-east-1&localTTLStore=file&localTTLStorePath=/data/subtreestore-ttl
subtreestore.allinone.miner.AP              = s3:///ap-ubsv-subtree-store?region=ap-south-1&localTTLStore=file&localTTLStorePath=/data/subtreestore-ttl
subtreestore.scaling.m1                     = lustre://s3.eu-west-1.amazonaws.com/ubsv-m1-subtree-store?region=eu-west-1&localDir=/data/subtreestore&localPersist=s3
subtreestore.scaling.m2                     = lustre://s3.us-east-1.amazonaws.com/ubsv-m2-subtree-store?region=us-east-1&localDir=/data/subtreestore&localPersist=s3
subtreestore.scaling.m3                     = lustre://s3.ap-south-1.amazonaws.com/ubsv-m3-subtree-store?region=ap-south-1&localDir=/data/subtreestore&localPersist=s3
subtreestore.scaling.m4                     = lustre://s3.ap-northeast-2.amazonaws.com/ubsv-m4-subtree-store?region=ap-northeast-2&localDir=/data/subtreestore&localPersist=s3
subtreestore.scaling.m5                     = lustre://s3.ca-central-1.amazonaws.com/ubsv-m5-subtree-store?region=ca-central-1&localDir=/data/subtreestore&localPersist=s3
subtreestore.scaling.m6                     = lustre://s3.us-west-2.amazonaws.com/ubsv-m6-subtree-store?region=us-west-2&localDir=/data/subtreestore&localPersist=s3
subtreestore.testing                        = lustre://s3.eu-central-1.amazonaws.com/ubsv-${clientName}-subtree-store?region=eu-central-1&localDir=/data/${clientName}/subtreestore&localPersist=s3

subtree_quorum_path = ./data/subtree_quorum
subtree_quorum_path.docker.host.ubsv1 = ./data/ubsv1/subtreestore/subtree_quorum
subtree_quorum_path.docker.host.ubsv2 = ./data/ubsv2/subtree_quorum
subtree_quorum_path.docker.host.ubsv3 = ./data/ubsv3/subtree_quorum
subtree_quorum_path.scaling = /data/subtreestore/quorum
subtree_quorum_path.testing = /data/${clientName}/subtreestore/quorum

# the ba-subtreestore is used by the block assembly and asset services to store the block assembly subtrees
## subtreestore.scaling.m1=s3:///eu-ubsv-subtree-store?region=eu-west-1&localTTLStore=file&localTTLStorePath=/data/ba-subtreestore
# the bv-subtreestore is used by the block validation service to store the block validation subtrees
# block assembly also mounts the block validation directory as a read only volume to use as a cache
## subtreestore.scaling.m1.blockvalidation=s3:///eu-ubsv-subtree-store?region=eu-west-1&localTTLStore=file&localTTLStorePath=/data/bv-subtreestore
## subtreestore.scaling.m2=s3:///us-ubsv-subtree-store?region=us-east-1&localTTLStore=file&localTTLStorePath=/data/ba-subtreestore
## subtreestore.scaling.m2.blockvalidation=s3:///us-ubsv-subtree-store?region=us-east-1&localTTLStore=file&localTTLStorePath=/data/bv-subtreestore
## subtreestore.scaling.m3=s3:///ap-ubsv-subtree-store?region=ap-south-1&localTTLStore=file&localTTLStorePath=/data/ba-subtreestore
## subtreestore.scaling.m3.blockvalidation=s3:///ap-ubsv-subtree-store?region=ap-south-1&localTTLStore=file&localTTLStorePath=/data/bv-subtreestore

# Block Persister Service Configuration
# ----------------------------------------
startBlockPersister=false
startBlockPersister.docker=true
startBlockPersister.dev=true
startBlockPersister.scaling=false
startBlockPersister.testing=false
startBlockPersister.docker.ci.ubsv1.blockassemblyTest=false
startBlockPersister.docker.ci.ubsv2.blockassemblyTest=false
startBlockPersister.docker.ci.ubsv3.blockassemblyTest=false

blockPersister_workingDir=./data/blockstore
blockPersister_workingDir.docker=/data/blockstore
blockPersister_workingDir.scaling=/data/blockstore
blockPersister_workingDir.testing=/data/${clientName}/blockstore

blockPersister_processUTXOSets=false

blockstore                                = badger:///data/blockstore?localTTLStore=file&localTTLStorePath=data/blockstore-ttl-1|data/blockstore-ttl-2
blockstore.dev                            = null:///?localTTLStore=file&localTTLStorePath=./data/blockstore-ttl
blockstore.docker                         = file:///data/blockstore
blockstore.docker.host.ubsv1              = file:///data/ubsv1/blockstore
blockstore.docker.host.ubsv2              = file:///data/ubsv2/blockstore
blockstore.docker.host.ubsv3              = file:///data/ubsv3/blockstore
blockstore.docker.ci.ubsv3.debug          = file:///data/ubsv3/blockstore
blockstore.docker.ci.tc1.run              = file:///../../data/ubsv1/blockstore
blockstore.docker.ci.ubsv1.tc1.run        = file:///../../data/ubsv1/blockstore
blockstore.docker.ci.ubsv2.tc1.run        = file:///../../data/ubsv2/blockstore
blockstore.docker.ci.ubsv2.tc2.run        = file:///../../data/ubsv2/blockstore
blockstore.docker.ci.ubsv3.tc1.run        = file:///../../data/ubsv3/blockstore

blockstore.dev.simon                      = file:///data/blockstore
blockstore.scaling.m1                     = lustre://s3.eu-west-1.amazonaws.com/ubsv-m1-block-store?region=eu-west-1&localDir=/data/blockstore&localPersist=s3
blockstore.scaling.m2                     = lustre://s3.us-east-1.amazonaws.com/ubsv-m2-block-store?region=us-east-1&localDir=/data/blockstore&localPersist=s3
blockstore.scaling.m3                     = lustre://s3.ap-south-1.amazonaws.com/ubsv-m3-block-store?region=ap-south-1&localDir=/data/blockstore&localPersist=s3
blockstore.scaling.m4                     = lustre://s3.ap-northeast-2.amazonaws.com/ubsv-m4-block-store?region=ap-northeast-2&localDir=/data/blockstore&localPersist=s3
blockstore.scaling.m5                     = lustre://s3.ca-central-1.amazonaws.com/ubsv-m5-block-store?region=ca-central-1&localDir=/data/blockstore&localPersist=s3
blockstore.scaling.m6                     = lustre://s3.us-west-2.amazonaws.com/ubsv-m6-block-store?region=us-west-2&localDir=/data/blockstore&localPersist=s3
blockstore.testing                     = lustre://s3.eu-central-1.amazonaws.com/ubsv-${clientName}-block-store?region=eu-central-1&localDir=/data/${clientName}/blockstore&localPersist=s3

blockstore_m1                     = s3://s3.eu-west-1.amazonaws.com/ubsv-m1-block-store?region=eu-west-1
blockstore_m2                     = s3://s3.us-east-1.amazonaws.com/ubsv-m2-block-store?region=us-east-1
blockstore_m3                     = s3://s3.ap-south-1.amazonaws.com/ubsv-m3-block-store?region=ap-south-1
blockstore_m4                     = s3://s3.ap-northeast-2.amazonaws.com/ubsv-m4-block-store?region=ap-northeast-2
blockstore_m5                     = s3://s3.ca-central-1.amazonaws.com/ubsv-m5-block-store?region=ca-central-1
blockstore_m6                     = s3://s3.us-west-2.amazonaws.com/ubsv-m6-block-store?region=us-west-2
blockstore_t1                     = s3://s3.eu-central-1.amazonaws.com/ubsv-t1-block-store?region=eu-central-1
blockstore_t2                     = s3://s3.eu-central-1.amazonaws.com/ubsv-t2-block-store?region=eu-central-1
blockstore_t3                     = s3://s3.eu-central-1.amazonaws.com/ubsv-t3-block-store?region=eu-central-1

block_quorum_path = ./data/blockstore_quorum
block_quorum_path.scaling = /data/blockstore/quorum
block_quorum_path.testing = /data/${clientName}/blockstore/quorum


subtree_kafkaWorkers=0
subtree_kafkaWorkers.dev.kafka=32
subtree_kafkaWorkers.scaling=1
subtree_kafkaWorkers.testing=1

block_kafkaWorkers=0
block_kafkaWorkers.dev.kafka=1
block_kafkaWorkers.scaling=1
block_kafkaWorkers.testing=1


# block concurrency settings
block_getAndValidateSubtreesConcurrency.scaling=32
block_checkDuplicateTransactionsConcurrency.scaling=32
block_validOrderAndBlessedConcurrency.scaling=32
block_getAndValidateSubtreesConcurrency.testing=32
block_checkDuplicateTransactionsConcurrency.testing=32
block_validOrderAndBlessedConcurrency.testing=32

# Validator Service Configuration
# ----------------------------------------
startValidator=false

useLocalValidator=true

validator_sendBatchSize=0
validator_sendBatchTimeout=100
validator_sendBatchWorkers=1

# tx validator sending batches to blockvalidation
validator_blockvalidation_maxRetries=5
validator_blockvalidation_retrySleep=2s
# delay before sending batch to blockvalidation, use for testing subtree processing retries
validator_blockvalidation_delay=0


validator_grpcListenAddress=:${VALIDATOR_GRPC_PORT}
validator_grpcListenAddress.dev=localhost:${VALIDATOR_GRPC_PORT}
validator_grpcListenAddress.docker.host.ubsv1=localhost:1${VALIDATOR_GRPC_PORT}
validator_grpcListenAddress.docker.host.ubsv2=localhost:2${VALIDATOR_GRPC_PORT}
validator_grpcListenAddress.docker.host.ubsv3=localhost:3${VALIDATOR_GRPC_PORT}

validator_grpcAddress=localhost:${VALIDATOR_GRPC_PORT}
validator_grpcAddress.docker.ci.ubsv1=ubsv-1:${VALIDATOR_GRPC_PORT}
validator_grpcAddress.docker.ci.ubsv2=ubsv-2:${VALIDATOR_GRPC_PORT}
validator_grpcAddress.docker.ci.ubsv3=ubsv-3:${VALIDATOR_GRPC_PORT}
validator_grpcAddress.docker.ci.ubsv3.debug=localhost:${VALIDATOR_GRPC_PORT}
validator_grpcAddress.docker.host.ubsv1=localhost:1${VALIDATOR_GRPC_PORT}
validator_grpcAddress.docker.host.ubsv2=localhost:2${VALIDATOR_GRPC_PORT}
validator_grpcAddress.docker.host.ubsv3=localhost:3${VALIDATOR_GRPC_PORT}
validator_grpcAddress.scaling.m1=k8s:///validation-service1.m1.svc.cluster.local:${VALIDATOR_GRPC_PORT}
validator_grpcAddress.scaling.m2=k8s:///validation-service2.m2.svc.cluster.local:${VALIDATOR_GRPC_PORT}
validator_grpcAddress.scaling.m3=k8s:///validation-service3.m3.svc.cluster.local:${VALIDATOR_GRPC_PORT}
validator_grpcAddress.scaling.m4=k8s:///validation-service4.m4.svc.cluster.local:${VALIDATOR_GRPC_PORT}
validator_grpcAddress.scaling.m5=k8s:///validation-service5.m5.svc.cluster.local:${VALIDATOR_GRPC_PORT}
validator_grpcAddress.scaling.m6=k8s:///validation-service6.m6.svc.cluster.local:${VALIDATOR_GRPC_PORT}
validator_grpcAddress.testing.t1=k8s:///validation-service-t1.t1.svc.cluster.local:${VALIDATOR_GRPC_PORT}
validator_grpcAddress.testing.t2=k8s:///validation-service-t2.t2.svc.cluster.local:${VALIDATOR_GRPC_PORT}
validator_grpcAddress.testing.t3=k8s:///validation-service-t3.t3.svc.cluster.local:${VALIDATOR_GRPC_PORT}


# Block Assembly Service Configuration
# ----------------------------------------
startBlockAssembly=true
startBlockAssembly.scaling=false
startBlockAssembly.testing=false

blockassembly_disabled=false

blockassembly_sendBatchSize=100
blockassembly_sendBatchSize.scaling=1024
blockassembly_sendBatchSize.testing=1024

blockassembly_sendBatchTimeout=2
blockassembly_sendBatchTimeout.scaling=20
blockassembly_sendBatchTimeout.testing=20

# the local TTL cache is only used when remote TTL stores are enabled
blockassembly_localTTLCache=
#blockassembly_localTTLCache.scaling=/data/subtreestore-ttl-1|/data/subtreestore-ttl-2|/data/subtreestore-ttl-3|/data/subtreestore-ttl-4

blockassembly_auxiliarySubtreeStore=
#blockassembly_auxiliarySubtreeStore.scaling=/data/bv-subtreestore

blockassembly_maxBlockReorgRollback=100
blockassembly_maxBlockReorgRollback.scaling=500
blockassembly_maxBlockReorgRollback.testing=500

blockassembly_maxBlockReorgCatchup=100
blockassembly_maxBlockReorgCatchup.scaling=2000
blockassembly_maxBlockReorgCatchup.testing=2000

blockassembly_subtreeProcessorBatcherSize=1000
blockassembly_subtreeProcessorBatcherSize.scaling=10000000
blockassembly_subtreeProcessorBatcherSize.testing=10000000

blockassembly_subtreeProcessorConcurrentReads.scaling=375
blockassembly_subtreeProcessorConcurrentReads.testing=375
blockassembly_processRemainderTxHashesConcurrency.scaling=375
blockassembly_processRemainderTxHashesConcurrency.testing=375
blockassembly_moveDownBlockConcurrency.scaling=375
blockassembly_moveDownBlockConcurrency.testing=375

blockassembly_grpcListenAddress=:${BLOCK_ASSEMBLY_GRPC_PORT}
blockassembly_grpcListenAddress.dev=localhost:${BLOCK_ASSEMBLY_GRPC_PORT}
blockassembly_grpcListenAddress.docker.host.ubsv1=localhost:1${BLOCK_ASSEMBLY_GRPC_PORT}
blockassembly_grpcListenAddress.docker.host.ubsv2=localhost:2${BLOCK_ASSEMBLY_GRPC_PORT}
blockassembly_grpcListenAddress.docker.host.ubsv3=localhost:3${BLOCK_ASSEMBLY_GRPC_PORT}

blockassembly_grpcAddress=localhost:${BLOCK_ASSEMBLY_GRPC_PORT}
blockassembly_grpcAddress.docker=localhost:${BLOCK_ASSEMBLY_GRPC_PORT}
blockassembly_grpcAddress.docker.ci.ubsv1=ubsv-1:${BLOCK_ASSEMBLY_GRPC_PORT}
blockassembly_grpcAddress.docker.ci.ubsv2=ubsv-2:${BLOCK_ASSEMBLY_GRPC_PORT}
blockassembly_grpcAddress.docker.ci.ubsv3=ubsv-3:${BLOCK_ASSEMBLY_GRPC_PORT}
blockassembly_grpcAddress.docker.ci.ubsv3.debug=localhost:${BLOCK_ASSEMBLY_GRPC_PORT}
blockassembly_grpcAddress.docker.ci.tc1.run=localhost:1${BLOCK_ASSEMBLY_GRPC_PORT}
blockassembly_grpcAddress.docker.host.ubsv1=localhost:1${BLOCK_ASSEMBLY_GRPC_PORT}
blockassembly_grpcAddress.docker.host.ubsv2=localhost:2${BLOCK_ASSEMBLY_GRPC_PORT}
blockassembly_grpcAddress.docker.host.ubsv3=localhost:3${BLOCK_ASSEMBLY_GRPC_PORT}
blockassembly_grpcAddress.scaling.m1=k8s:///blockassembly-service1.m1.svc.cluster.local:${BLOCK_ASSEMBLY_GRPC_PORT}
blockassembly_grpcAddress.scaling.m2=k8s:///blockassembly-service2.m2.svc.cluster.local:${BLOCK_ASSEMBLY_GRPC_PORT}
blockassembly_grpcAddress.scaling.m3=k8s:///blockassembly-service3.m3.svc.cluster.local:${BLOCK_ASSEMBLY_GRPC_PORT}
blockassembly_grpcAddress.scaling.m4=k8s:///blockassembly-service4.m4.svc.cluster.local:${BLOCK_ASSEMBLY_GRPC_PORT}
blockassembly_grpcAddress.scaling.m5=k8s:///blockassembly-service5.m5.svc.cluster.local:${BLOCK_ASSEMBLY_GRPC_PORT}
blockassembly_grpcAddress.scaling.m6=k8s:///blockassembly-service6.m6.svc.cluster.local:${BLOCK_ASSEMBLY_GRPC_PORT}
blockassembly_grpcAddress.scaling.m6=k8s:///blockassembly-service6.m6.svc.cluster.local:${BLOCK_ASSEMBLY_GRPC_PORT}
blockassembly_grpcAddress.scaling.m6=k8s:///blockassembly-service6.m6.svc.cluster.local:${BLOCK_ASSEMBLY_GRPC_PORT}
blockassembly_grpcAddress.scaling.m6=k8s:///blockassembly-service6.m6.svc.cluster.local:${BLOCK_ASSEMBLY_GRPC_PORT}
blockassembly_grpcAddress.testing.t1=k8s:///blockassembly-service-t1.t1.svc.cluster.local:${BLOCK_ASSEMBLY_GRPC_PORT}
blockassembly_grpcAddress.testing.t2=k8s:///blockassembly-service-t2.t2.svc.cluster.local:${BLOCK_ASSEMBLY_GRPC_PORT}
blockassembly_grpcAddress.testing.t3=k8s:///blockassembly-service-t3.t3.svc.cluster.local:${BLOCK_ASSEMBLY_GRPC_PORT}

blockassembly_kafkaWorkers=0
blockassembly_kafkaWorkers.dev.kafka=1
blockassembly_kafkaWorkers.dev.liam=0

# kafka turned off for now
blockassembly_kafkaWorkers.scaling=0
blockassembly_kafkaWorkers.testing=0


initial_merkle_items_per_subtree=1048576
initial_merkle_items_per_subtree.dev=32768
initial_merkle_items_per_subtree.docker=1024
initial_merkle_items_per_subtree.allinone=32768
initial_merkle_items_per_subtree.docker.ci.ubsv1.blockassemblyTest=32

# Difficulty configuration
# dificulty_adjustment controls whether the difficulty will change
difficulty_adjustment=false
difficulty_adjustment.dev=false
difficulty_adjustment.scaling=false
difficulty_adjustment.testing=false

difficulty_adjustment_window=144 # blocks

difficulty_target_time_per_block=600 # seconds
difficulty_target_time_per_block.dev=60
difficulty_target_time_per_block.test=144

difficulty_pow_limit=234
difficulty_pow_limit.scaling=224
difficulty_pow_limit.testing=224

mining_n_bits=2000ffff
mining_n_bits.dev.liam=1d7fff80

# Subtree Validation Service Configuration
# ----------------------------------------
startSubtreeValidation=true
startSubtreeValidation.scaling=false
startSubtreeValidation.testing=false

subtreevalidation_grpcListenAddress=:${SUBTREE_VALIDATION_GRPC_PORT}
subtreevalidation_grpcListenAddress.dev=localhost:${SUBTREE_VALIDATION_GRPC_PORT}
subtreevalidation_grpcListenAddress.docker.host.ubsv1=localhost:1${SUBTREE_VALIDATION_GRPC_PORT}
subtreevalidation_grpcListenAddress.docker.host.ubsv2=localhost:2${SUBTREE_VALIDATION_GRPC_PORT}
subtreevalidation_grpcListenAddress.docker.host.ubsv3=localhost:3${SUBTREE_VALIDATION_GRPC_PORT}

subtreevalidation_grpcAddress=localhost:${SUBTREE_VALIDATION_GRPC_PORT}
subtreevalidation_grpcAddress.docker.host.ubsv1=localhost:1${SUBTREE_VALIDATION_GRPC_PORT}
subtreevalidation_grpcAddress.docker.host.ubsv2=localhost:2${SUBTREE_VALIDATION_GRPC_PORT}
subtreevalidation_grpcAddress.docker.host.ubsv3=localhost:3${SUBTREE_VALIDATION_GRPC_PORT}
subtreevalidation_grpcAddress.scaling.m1=k8s:///subtreevalidation-service1.m1.svc.cluster.local:${SUBTREE_VALIDATION_GRPC_PORT}
subtreevalidation_grpcAddress.scaling.m2=k8s:///subtreevalidation-service2.m2.svc.cluster.local:${SUBTREE_VALIDATION_GRPC_PORT}
subtreevalidation_grpcAddress.scaling.m3=k8s:///subtreevalidation-service3.m3.svc.cluster.local:${SUBTREE_VALIDATION_GRPC_PORT}
subtreevalidation_grpcAddress.scaling.m4=k8s:///subtreevalidation-service4.m4.svc.cluster.local:${SUBTREE_VALIDATION_GRPC_PORT}
subtreevalidation_grpcAddress.scaling.m5=k8s:///subtreevalidation-service5.m5.svc.cluster.local:${SUBTREE_VALIDATION_GRPC_PORT}
subtreevalidation_grpcAddress.scaling.m6=k8s:///subtreevalidation-service6.m6.svc.cluster.local:${SUBTREE_VALIDATION_GRPC_PORT}
subtreevalidation_grpcAddress.testing.t1=k8s:///subtreevalidation-service-t1.t1.svc.cluster.local:${SUBTREE_VALIDATION_GRPC_PORT}
subtreevalidation_grpcAddress.testing.t2=k8s:///subtreevalidation-service-t2.t2.svc.cluster.local:${SUBTREE_VALIDATION_GRPC_PORT}
subtreevalidation_grpcAddress.testing.t3=k8s:///subtreevalidation-service-t3.t3.svc.cluster.local:${SUBTREE_VALIDATION_GRPC_PORT}

# quick validation means it only uses the txmeta cache
# (ignored if subtreevalidation_validation_max_retries is 0)
subtreevalidation_failfast_validation=true
subtreevalidation_failfast_validation.docker=false

# cache miss threshold is the number of missing txs to allow before we fail
subtreevalidation_processTxMetaUsingCache_MissingTxThreshold=1

# store miss threshold is the number of missing txs when searching our store, ignored during BlockVaidation
subtreevalidation_processTxMetaUsingStore_MissingTxThreshold=1

# abandon subtree validation when missing total exceeds threshold, ignored during BlockVaidation
subtreevalidation_subtree_validation_abandon_threshold=1
subtreevalidation_validation_max_retries=30
subtreevalidation_validation_retry_sleep=5s

subtreevalidation_subtreeValidationTimeout=1000


# subtree validation concurrency settings

# this is basically making subtree processing unlimited
# it is very important that new subtrees are processed as fast as possible
subtreevalidation_subtreeFoundChConcurrency=1
subtreevalidation_subtreeFoundChConcurrency.docker=1
subtreevalidation_subtreeFoundChConcurrency.scaling=128
subtreevalidation_subtreeFoundChConcurrency.testing=128

subtreevalidation_processTxMetaUsingCache_BatchSize=1024
subtreevalidation_processTxMetaUsingStore_BatchSize=1024

subtreevalidation_processTxMetaUsingCache_Concurrency=32
subtreevalidation_processTxMetaUsingStore_Concurrency=32

subtreevalidation_getMissingTransactions=32
# limit this, this is happening in the background
subtreevalidation_subtreeTTLConcurrency=8

# minutes to keep subtrees in the cache
# default is 120 (minutes)
blockassembly_subtreeTTL.docker.host=0
# default is 120 (minutes)
subtreevalidation_subtreeTTL.docker.host=0

subtreevalidation_txMetaCacheBatcherEnabled=true
subtreevalidation_txMetaCacheBatcherEnabled.dev.liam=false
subtreevalidation_txMetaCacheBatcherEnabled.dev.kafka=false

# Makes this false to disable sending tx meta data to block validation via frpc
subtreevalidation_txMetaCacheBatcherEnabled.scaling=false
subtreevalidation_txMetaCacheBatcherEnabled.testing=false

subtreevalidation_txMetaCacheBatchSize=300
subtreevalidation_txMetaCacheBatchTimeoutMillis=2
subtreevalidation_txMetaCacheBatcherSendTimeout=1s

subtreevalidation_txMetaCacheEnabled=true

subtreevalidation_kafkaWorkers=0
subtreevalidation_kafkaWorkers.dev.kafka=1
subtreevalidation_kafkaWorkers.dev.liam=1
subtreevalidation_kafkaWorkers.scaling=32
subtreevalidation_kafkaWorkers.testing=32
# turned off for M3 for now, we do not have a Kafka there yet



# Block Validation Service Configuration
# ----------------------------------------
startBlockValidation=true
startBlockValidation.scaling=false
startBlockValidation.testing=false
startBlockValidation.docker.ci.ubsv1.blockassemblyTest=false
startBlockValidation.docker.ci.ubsv2.blockassemblyTest=false
startBlockValidation.docker.ci.ubsv3.blockassemblyTest=false

# quick validation means it only uses the txmeta cache
# (ignored if blockvalidation_validation_max_retries is 0)
blockvalidation_fail_fast_validation=true
blockvalidation_fail_fast_validation.docker=false

# cache miss threshold is the number of missing txs to allow before we fail
blockvalidation_processTxMetaUsingCache_MissingTxThreshold=1

# store miss threshold is the number of missing txs when searching our store, ignored during BlockVaidation
blockvalidation_processTxMetaUsingStore_MissingTxThreshold=1

# abandon subtree validation when missing total exceeds threshold, ignored during BlockValidation
blockvalidation_subtree_validation_abandon_threshold=1
blockvalidation_subtree_validation_abandon_threshold.scaling=1000
blockvalidation_subtree_validation_abandon_threshold.testing=1000

blockvalidation_validation_max_retries=3
blockvalidation_validation_retry_sleep=5s

blockvalidation_subtreeValidationTimeout=1000

# block validation concurrency settings

# this is basically making subtree processing unlimited
# it is very important that new subtrees are processed as fast as possible
blockvalidation_subtreeFoundChConcurrency=1
blockvalidation_subtreeFoundChConcurrency.docker=1
blockvalidation_subtreeFoundChConcurrency.scaling=128
blockvalidation_subtreeFoundChConcurrency.testing=128

blockvalidation_processTxMetaUsingCache_BatchSize=1024
blockvalidation_processTxMetaUsingStore_BatchSize=1024

blockvalidation_processTxMetaUsingCache_Concurrency=32
blockvalidation_processTxMetaUsingStore_Concurrency=32

blockvalidation_getMissingTransactions=32
blockvalidation_localSetTxMinedConcurrency=8
# limit this, this is happening in the background
blockvalidation_finalizeBlockValidationConcurrency=8
# limit this, this is happening in the background
blockvalidation_subtreeTTLConcurrency=8
blockvalidation_validateBlockSubtreesConcurrency=32

blockvalidation_grpcListenAddress=:${BLOCK_VALIDATION_GRPC_PORT}
blockvalidation_grpcListenAddress.dev=localhost:${BLOCK_VALIDATION_GRPC_PORT}
blockvalidation_grpcListenAddress.docker.host.ubsv1=localhost:1${BLOCK_VALIDATION_GRPC_PORT}
blockvalidation_grpcListenAddress.docker.host.ubsv2=localhost:2${BLOCK_VALIDATION_GRPC_PORT}
blockvalidation_grpcListenAddress.docker.host.ubsv3=localhost:3${BLOCK_VALIDATION_GRPC_PORT}

blockvalidation_httpListenAddress=:${BLOCK_VALIDATION_HTTP_PORT}
blockvalidation_httpListenAddress.dev=localhost:${BLOCK_VALIDATION_HTTP_PORT}
blockvalidation_httpListenAddress.docker.host.ubsv1=localhost:1${BLOCK_VALIDATION_HTTP_PORT}
blockvalidation_httpListenAddress.docker.host.ubsv2=localhost:2${BLOCK_VALIDATION_HTTP_PORT}
blockvalidation_httpListenAddress.docker.host.ubsv31=localhost:3${BLOCK_VALIDATION_HTTP_PORT}

blockvalidation_httpAddress=http://localhost:${BLOCK_VALIDATION_HTTP_PORT}
blockvalidation_httpAddress.docker.ci.ubsv1=http://ubsv-1:${BLOCK_VALIDATION_HTTP_PORT}
blockvalidation_httpAddress.docker.ci.ubsv2=http://ubsv-2:${BLOCK_VALIDATION_HTTP_PORT}
blockvalidation_httpAddress.docker.ci.ubsv3=http://ubsv-3:${BLOCK_VALIDATION_HTTP_PORT}
blockvalidation_httpAddress.docker.ci.ubsv3.debug=http://localhost:${BLOCK_VALIDATION_HTTP_PORT}
blockvalidation_httpAddress.docker.host.ubsv1=http://localhost:1${BLOCK_VALIDATION_HTTP_PORT}
blockvalidation_httpAddress.docker.host.ubsv2=http://localhost:2${BLOCK_VALIDATION_HTTP_PORT}
blockvalidation_httpAddress.docker.host.ubsv3=http://localhost:3${BLOCK_VALIDATION_HTTP_PORT}
blockvalidation_httpAddress.scaling.m1=http://blockvalidation-service1.m1.svc.cluster.local:${BLOCK_VALIDATION_HTTP_PORT}
blockvalidation_httpAddress.scaling.m2=http://blockvalidation-service2.m2.svc.cluster.local:${BLOCK_VALIDATION_HTTP_PORT}
blockvalidation_httpAddress.scaling.m3=http://blockvalidation-service3.m3.svc.cluster.local:${BLOCK_VALIDATION_HTTP_PORT}
blockvalidation_httpAddress.scaling.m4=http://blockvalidation-service4.m4.svc.cluster.local:${BLOCK_VALIDATION_HTTP_PORT}
blockvalidation_httpAddress.scaling.m5=http://blockvalidation-service5.m5.svc.cluster.local:${BLOCK_VALIDATION_HTTP_PORT}
blockvalidation_httpAddress.scaling.m6=http://blockvalidation-service6.m6.svc.cluster.local:${BLOCK_VALIDATION_HTTP_PORT}
blockvalidation_httpAddress.testing.t1=http://blockvalidation-service-t1.t1.svc.cluster.local:${BLOCK_VALIDATION_HTTP_PORT}
blockvalidation_httpAddress.testing.t2=http://blockvalidation-service-t2.t2.svc.cluster.local:${BLOCK_VALIDATION_HTTP_PORT}
blockvalidation_httpAddress.testing.t3=http://blockvalidation-service-t3.t3.svc.cluster.local:${BLOCK_VALIDATION_HTTP_PORT}

blockvalidation_grpcAddress=localhost:${BLOCK_VALIDATION_GRPC_PORT}
blockvalidation_grpcAddress.docker.host.ubsv1=localhost:1${BLOCK_VALIDATION_GRPC_PORT}
blockvalidation_grpcAddress.docker.host.ubsv2=localhost:2${BLOCK_VALIDATION_GRPC_PORT}
blockvalidation_grpcAddress.docker.host.ubsv3=localhost:3${BLOCK_VALIDATION_GRPC_PORT}
blockvalidation_grpcAddress.scaling.m1=k8s:///blockvalidation-service1.m1.svc.cluster.local:${BLOCK_VALIDATION_GRPC_PORT}
blockvalidation_grpcAddress.scaling.m2=k8s:///blockvalidation-service2.m2.svc.cluster.local:${BLOCK_VALIDATION_GRPC_PORT}
blockvalidation_grpcAddress.scaling.m3=k8s:///blockvalidation-service3.m3.svc.cluster.local:${BLOCK_VALIDATION_GRPC_PORT}
blockvalidation_grpcAddress.scaling.m4=k8s:///blockvalidation-service4.m4.svc.cluster.local:${BLOCK_VALIDATION_GRPC_PORT}
blockvalidation_grpcAddress.scaling.m5=k8s:///blockvalidation-service5.m5.svc.cluster.local:${BLOCK_VALIDATION_GRPC_PORT}
blockvalidation_grpcAddress.scaling.m6=k8s:///blockvalidation-service6.m6.svc.cluster.local:${BLOCK_VALIDATION_GRPC_PORT}
blockvalidation_grpcAddress.testing.t1=k8s:///blockvalidation-service-t1.t1.svc.cluster.local:${BLOCK_VALIDATION_GRPC_PORT}
blockvalidation_grpcAddress.testing.t2=k8s:///blockvalidation-service-t2.t2.svc.cluster.local:${BLOCK_VALIDATION_GRPC_PORT}
blockvalidation_grpcAddress.testing.t3=k8s:///blockvalidation-service-t3.t3.svc.cluster.local:${BLOCK_VALIDATION_GRPC_PORT}

blockvalidation_kafkaWorkers=0
blockvalidation_kafkaWorkers.dev.kafka=1
blockvalidation_kafkaWorkers.dev.liam=0
# turned off for M3 for now, we do not have a Kafka there yet

blockvalidation_kafkaWorkers.scaling=32
blockvalidation_kafkaWorkers.testing=32

# Tx Meta Data Store Service Configuration
# ----------------------------------------
txMetaCacheMaxMB=256 #512MB
txMetaCacheMaxMB.docker=128
txMetaCacheMaxMB.scaling=131072 # 128GB - around 1.3B - 1.5B txs
txMetaCacheMaxMB.testing=131072 # 128GB - around 1.3B - 1.5B txs

txMetaCacheTrimRatio=5
txMetaCacheTrimRatio.scaling=5
txMetaCacheTrimRatio.testing=5

blockMinedCacheMaxMB=256
blockMinedCacheMaxMB.docker=32

utxostore_maxMinedBatchSize=1024
utxostore_maxMinedBatchSize.scaling=9000 # 102400
utxostore_maxMinedBatchSize.testing=9000 # 102400

utxostore_maxMinedRoutines=4
utxostore_maxMinedRoutines.scaling=32
utxostore_maxMinedRoutines.testing=32


# UTXO Store Service Configuration
# ----------------------------------------
utxostore_dbTimeoutMillis=5000

utxostore_batchingEnabled=false

utxostore_spendBatcherSize=100
utxostore_spendBatcherSize.scaling=512
utxostore_spendBatcherSize.testing=512
utxostore_spendBatcherDurationMillis=100
utxostore_spendBatcherDurationMillis.scaling=10
utxostore_spendBatcherDurationMillis.testing=10

utxostore_storeBatcherSize=100
utxostore_storeBatcherSize.scaling=512 # 1.1M / 22 (propagations) / 200 (5ms delay -> 200/s)
utxostore_storeBatcherSize.testing=512 # 1.1M / 22 (propagations) / 200 (5ms delay -> 200/s)
utxostore_storeBatcherDurationMillis=100
utxostore_storeBatcherDurationMillis.scaling=10
utxostore_storeBatcherDurationMillis.testing=10


# 54000 # 15 hours - we have the space
utxostore                                       = null:///
utxostore.dev                                   = sqlite:///utxostore?expiration=300
utxostore.dev.legacy                            = aerospike2://localhost:3000/test?set=utxo
# utxostore.dev.liam                            = aerospike://localhost:3000/ubsv-store?set=utxo&expiration=4294967295
utxostore.dev.liam                              = postgres://ubsv:ubsv@localhost:5432/ubsv?expiration=300
utxostore.dev.simon                             = postgres://ubsv:ubsv@localhost:5432/ubsv?expiration=300
utxostore.dev.stu                               = postgres://ubsv:ubsv@localhost:5432/ubsv?expiration=300
# utxostore.dev.stu                             = aerospike://localhost:3000/test
utxostore.docker.ci.chainintegrity.ubsv1        = postgres://miner1:miner1@localhost:5432/ubsv1?expiration=300
utxostore.docker.ci.chainintegrity.ubsv2        = postgres://miner2:miner2@localhost:5432/ubsv2?expiration=300
utxostore.docker.ci.chainintegrity.ubsv3        = postgres://miner3:miner3@localhost:5432/ubsv3?expiration=300
utxostore.docker.ci.ubsv1.blockassemblyTest.run = postgres://miner1:miner1@localhost:5432/ubsv1?expiration=300
utxostore.docker.ci.ubsv2.blockassemblyTest.run = postgres://miner2:miner2@localhost:5432/ubsv2?expiration=300
utxostore.docker.ci.ubsv3.blockassemblyTest.run = postgres://miner3:miner3@localhost:5432/ubsv3?expiration=300
utxostore.docker.ci.externaltxblaster.ubsv1     = postgres://miner1:miner1@localhost:5432/ubsv1?expiration=300
utxostore.docker.ci.externaltxblaster.ubsv2     = postgres://miner2:miner2@localhost:5432/ubsv2?expiration=300
utxostore.docker.ci.externaltxblaster.ubsv3     = postgres://miner3:miner3@localhost:5432/ubsv3?expiration=300
utxostore.docker.ci.ubsv3.debug                 = postgres://miner3:miner3@localhost:5432/ubsv3?expiration=300
utxostore.docker.host.ubsv1                     = postgres://miner1:miner1@localhost:15432/ubsv1
utxostore.docker.host.ubsv2                     = postgres://miner2:miner2@localhost:15432/ubsv2
utxostore.docker.host.ubsv3                     = postgres://miner3:miner3@localhost:15432/ubsv3
utxostore.scaling.m1.chainintegrity             = aerospike://editor:password1234@aerospike-0.ubsv.internal:3000/utxo-store?set=utxo&WarmUp=0&ConnectionQueueSize=256&LimitConnectionsToQueueSize=true&MinConnectionsPerNode=256&expiration=21600 # 6 hours - we have the space
utxostore.scaling                               = aerospike://editor:password1234@aerospike-0.ubsv.internal:3000/utxo-store?set=utxo&WarmUp=0&ConnectionQueueSize=256&LimitConnectionsToQueueSize=true&MinConnectionsPerNode=256&expiration=21600 # 6 hours - we have the space
utxostore.scaling.m1.asset                      = aerospike://editor:password1234@aerospike-0.ubsv.internal:3000/utxo-store?set=utxo&WarmUp=0&ConnectionQueueSize=16&LimitConnectionsToQueueSize=true&MinConnectionsPerNode=16&expiration=21600 # 6 hours - we have the space
utxostore.scaling.m1.blockpersister             = aerospike://editor:password1234@aerospike-0.ubsv.internal:3000/utxo-store?set=utxo&WarmUp=0&ConnectionQueueSize=16&LimitConnectionsToQueueSize=true&MinConnectionsPerNode=16&expiration=21600 # 6 hours - we have the space
utxostore.scaling.m2.asset                      = aerospike://editor:password1234@aerospike-0.ubsv.internal:3000/utxo-store?set=utxo&WarmUp=0&ConnectionQueueSize=16&LimitConnectionsToQueueSize=true&MinConnectionsPerNode=16&expiration=21600 # 6 hours - we have the space
utxostore.scaling.m2.blockpersister             = aerospike://editor:password1234@aerospike-0.ubsv.internal:3000/utxo-store?set=utxo&WarmUp=0&ConnectionQueueSize=16&LimitConnectionsToQueueSize=true&MinConnectionsPerNode=16&expiration=21600 # 6 hours - we have the space
utxostore.scaling.m3.asset                      = aerospike://editor:password1234@aerospike-0.ubsv.internal:3000/utxo-store?set=utxo&WarmUp=0&ConnectionQueueSize=16&LimitConnectionsToQueueSize=true&MinConnectionsPerNode=16&expiration=21600 # 6 hours - we have the space
utxostore.scaling.m3.blockpersister             = aerospike://editor:password1234@aerospike-0.ubsv.internal:3000/utxo-store?set=utxo&WarmUp=0&ConnectionQueueSize=16&LimitConnectionsToQueueSize=true&MinConnectionsPerNode=16&expiration=21600 # 6 hours - we have the space
utxostore.scaling.m4.asset                      = aerospike://editor:password1234@aerospike-0.ubsv.internal:3000/utxo-store?set=utxo&WarmUp=0&ConnectionQueueSize=16&LimitConnectionsToQueueSize=true&MinConnectionsPerNode=16&expiration=21600 # 6 hours - we have the space
utxostore.scaling.m4.blockpersister             = aerospike://editor:password1234@aerospike-0.ubsv.internal:3000/utxo-store?set=utxo&WarmUp=0&ConnectionQueueSize=16&LimitConnectionsToQueueSize=true&MinConnectionsPerNode=16&expiration=21600 # 6 hours - we have the space
utxostore.scaling.m5.asset                      = aerospike://editor:password1234@aerospike-0.ubsv.internal:3000/utxo-store?set=utxo&WarmUp=0&ConnectionQueueSize=16&LimitConnectionsToQueueSize=true&MinConnectionsPerNode=16&expiration=21600 # 6 hours - we have the space
utxostore.scaling.m5.blockpersister             = aerospike://editor:password1234@aerospike-0.ubsv.internal:3000/utxo-store?set=utxo&WarmUp=0&ConnectionQueueSize=16&LimitConnectionsToQueueSize=true&MinConnectionsPerNode=16&expiration=21600 # 6 hours - we have the space
utxostore.scaling.m6.asset                      = aerospike://editor:password1234@aerospike-0.ubsv.internal:3000/utxo-store?set=utxo&WarmUp=0&ConnectionQueueSize=16&LimitConnectionsToQueueSize=true&MinConnectionsPerNode=16&expiration=21600 # 6 hours - we have the space
utxostore.scaling.m6.blockpersister             = aerospike://editor:password1234@aerospike-0.ubsv.internal:3000/utxo-store?set=utxo&WarmUp=0&ConnectionQueueSize=16&LimitConnectionsToQueueSize=true&MinConnectionsPerNode=16&expiration=21600 # 6 hours - we have the space
utxostore.testing.t1                        = aerospike://editor:password1234@t1aerospike-0.ubsv.internal:3000/utxo-store?set=utxo&WarmUp=0&ConnectionQueueSize=16&LimitConnectionsToQueueSize=true&MinConnectionsPerNode=8&expiration=21600 # 6 hours - we have the space
utxostore.testing.t2                        = aerospike://editor:password1234@t2aerospike-0.ubsv.internal:3000/utxo-store?set=utxo&WarmUp=0&ConnectionQueueSize=16&LimitConnectionsToQueueSize=true&MinConnectionsPerNode=8&expiration=21600 # 6 hours - we have the space
utxostore.testing.t3                        = aerospike://editor:password1234@t3aerospike-0.ubsv.internal:3000/utxo-store?set=utxo&WarmUp=0&ConnectionQueueSize=16&LimitConnectionsToQueueSize=true&MinConnectionsPerNode=8&expiration=21600 # 6 hours - we have the space


utxoblaster_utxostore_aerospike             = aerospike://editor:password1234@aerospike-0.ubsv.internal:3000/utxo-store?WarmUp=0&ConnectionQueueSize=640&LimitConnectionsToQueueSize=true&MinConnectionsPerNode=64&expiration=900
utxoblaster_utxostore_aerospike.dev         = aerospike://localhost:3000/test
utxoblaster_utxostore_aerospike.dev.liam    = aerospike://localhost:3000/utxo-store?WarmUp=0&ConnectionQueueSize=768&LimitConnectionsToQueueSize=true&MinConnectionsPerNode=76&expiration=900

REDIS_HOSTS=localhost:${REDIS_PORT}
# REDIS_HOSTS.dev=localhost:$},localhost:6380,localhost:6381,localhost:6382
REDIS_HOSTS.scaling=ubsv-store-redis-cluster-0.ubsv-store-redis-cluster-headless.redis.svc.cluster.local:$},ubsv-store-redis-cluster-1.ubsv-store-redis-cluster-headless.redis.svc.cluster.local:$},ubsv-store-redis-cluster-2.ubsv-store-redis-cluster-headless.redis.svc.cluster.local:$},ubsv-store-redis-cluster-3.ubsv-store-redis-cluster-headless.redis.svc.cluster.local:$},ubsv-store-redis-cluster-4.ubsv-store-redis-cluster-headless.redis.svc.cluster.local:$},ubsv-store-redis-cluster-5.ubsv-store-redis-cluster-headless.redis.svc.cluster.local:$}
utxoblaster_utxostore_redis=redis://${REDIS_HOSTS}

# how long to wait before deleting spent utxos (seconds)
spent_utxo_ttl=3600 #  = 1 hour
spent_utxo_ttl.dev=10 #  = 10 seconds
spent_utxo_ttl.docker=10 #  = 10 seconds


# Blockchain Service Configuration
# ----------------------------------------
startBlockchain=true
startBlockchain.scaling=false
startBlockchain.testing=false

blockchain_maxRetries.docker.host=3

blockchain_grpcListenAddress=:${BLOCKCHAIN_GRPC_PORT}
blockchain_grpcListenAddress.docker=0.0.0.0:${BLOCKCHAIN_GRPC_PORT}
blockchain_grpcListenAddress.docker.host.ubsv1=localhost:1${BLOCKCHAIN_GRPC_PORT}
blockchain_grpcListenAddress.docker.host.ubsv2=localhost:2${BLOCKCHAIN_GRPC_PORT}
blockchain_grpcListenAddress.docker.host.ubsv3=localhost:3${BLOCKCHAIN_GRPC_PORT}
blockchain_grpcListenAddress.dev=localhost:${BLOCKCHAIN_GRPC_PORT}
blockchain_grpcListenAddress.docker.ci.ubsv3.debug=:${BLOCKCHAIN_GRPC_PORT}

blockchain_grpcAddress=localhost:${BLOCKCHAIN_GRPC_PORT}
blockchain_grpcAddress.docker.ci.ubsv1=ubsv-1:${BLOCKCHAIN_GRPC_PORT}
blockchain_grpcAddress.docker.ci.ubsv2=ubsv-2:${BLOCKCHAIN_GRPC_PORT}
blockchain_grpcAddress.docker.ci.ubsv3=ubsv-3:${BLOCKCHAIN_GRPC_PORT}
blockchain_grpcAddress.docker.ci.ubsv3.debug=localhost:${BLOCKCHAIN_GRPC_PORT}
blockchain_grpcAddress.docker.ci.tc1.run=localhost:1${BLOCKCHAIN_GRPC_PORT}
blockchain_grpcAddress.docker.host.ubsv1=localhost:1${BLOCKCHAIN_GRPC_PORT}
blockchain_grpcAddress.docker.host.ubsv2=localhost:2${BLOCKCHAIN_GRPC_PORT}
blockchain_grpcAddress.docker.host.ubsv3=localhost:3${BLOCKCHAIN_GRPC_PORT}
blockchain_grpcAddress.scaling.m1=k8s:///blockchain-service1.m1.svc.cluster.local:${BLOCKCHAIN_GRPC_PORT}
blockchain_grpcAddress.scaling.m2=k8s:///blockchain-service2.m2.svc.cluster.local:${BLOCKCHAIN_GRPC_PORT}
blockchain_grpcAddress.scaling.m3=k8s:///blockchain-service3.m3.svc.cluster.local:${BLOCKCHAIN_GRPC_PORT}
blockchain_grpcAddress.scaling.m4=k8s:///blockchain-service4.m4.svc.cluster.local:${BLOCKCHAIN_GRPC_PORT}
blockchain_grpcAddress.scaling.m5=k8s:///blockchain-service5.m5.svc.cluster.local:${BLOCKCHAIN_GRPC_PORT}
blockchain_grpcAddress.scaling.m6=k8s:///blockchain-service6.m6.svc.cluster.local:${BLOCKCHAIN_GRPC_PORT}
blockchain_grpcAddress.testing.t1=k8s:///blockchain-service-t1.t1.svc.cluster.local:${BLOCKCHAIN_GRPC_PORT}
blockchain_grpcAddress.testing.t1.blockchain=localhost:${BLOCKCHAIN_GRPC_PORT}
blockchain_grpcAddress.testing.t2=k8s:///blockchain-service-t2.t2.svc.cluster.local:${BLOCKCHAIN_GRPC_PORT}
blockchain_grpcAddress.testing.t2.blockchain=localhost:${BLOCKCHAIN_GRPC_PORT}
blockchain_grpcAddress.testing.t3=k8s:///blockchain-service-t3.t3.svc.cluster.local:${BLOCKCHAIN_GRPC_PORT}
blockchain_grpcAddress.testing.t3.blockchain=localhost:${BLOCKCHAIN_GRPC_PORT}

blockchain_httpListenAddress=:${BLOCKCHAIN_HTTP_PORT}
blockchain_httpListenAddress.dev=localhost:${BLOCKCHAIN_HTTP_PORT}
blockchain_httpListenAddress.docker.host.ubsv1=localhost:1${BLOCKCHAIN_HTTP_PORT}
blockchain_httpListenAddress.docker.host.ubsv2=localhost:2${BLOCKCHAIN_HTTP_PORT}
blockchain_httpListenAddress.docker.host.ubsv3=localhost:3${BLOCKCHAIN_HTTP_PORT}

blockchain_store=sqlite:///blockchain
blockchain_store.dev.stu=postgres://ubsv:ubsv@localhost:5432/ubsv
blockchain_store.dev.simon=postgres://ubsv:ubsv@localhost:5432/ubsv
blockchain_store.dev.liam=postgres://ubsv:ubsv@localhost:5432/ubsv
blockchain_store.dev.legacy=postgres://ubsv:ubsv@localhost:5432/ubsv

blockchain_store.docker.ci.chainintegrity.ubsv1=postgres://miner1:miner1@localhost:5432/ubsv1
blockchain_store.docker.ci.chainintegrity.ubsv2=postgres://miner2:miner2@localhost:5432/ubsv2
blockchain_store.docker.ci.chainintegrity.ubsv3=postgres://miner3:miner3@localhost:5432/ubsv3
blockchain_store.docker.ci.ubsv1=postgres://miner1:miner1@localhost:5432/ubsv1
blockchain_store.docker.ci.ubsv2=postgres://miner2:miner2@localhost:5432/ubsv2
blockchain_store.docker.ci.ubsv3=postgres://miner3:miner3@localhost:5432/ubsv3
blockchain_store.docker.ci.externaltxblaster.ubsv1=postgres://miner1:miner1@localhost:5432/ubsv1
blockchain_store.docker.ci.externaltxblaster.ubsv2=postgres://miner2:miner2@localhost:5432/ubsv2
blockchain_store.docker.ci.externaltxblaster.ubsv3=postgres://miner3:miner3@localhost:5432/ubsv3
blockchain_store.docker.ci.ubsv3.debug=postgres://miner3:miner3@localhost:5432/ubsv3
blockchain_store.docker.host.ubsv1=postgres://miner1:miner1@localhost:15432/ubsv1
blockchain_store.docker.host.ubsv2=postgres://miner2:miner2@localhost:15432/ubsv2
blockchain_store.docker.host.ubsv3=postgres://miner3:miner3@localhost:15432/ubsv3











# sharing the same server





# Bootstrap Service Configuration
# ----------------------------------------
startBootstrap=false

# bootstrap_grpcListenAddress=:${BOOTSTRAP_GRPC_PORT}
# bootstrap_grpcListenAddress.dev=localhost:${BOOTSTRAP_GRPC_PORT}
# bootstrap_grpcListenAddress.docker=localhost:${BOOTSTRAP_GRPC_PORT}

# bootstrap_grpcAddress=localhost:${BOOTSTRAP_GRPC_PORT}
# bootstrap_grpcAddress.docker=localhost:${BOOTSTRAP_GRPC_PORT}
# bootstrap_grpcAddress.scaling.m1=bootstrap.scaling.ubsv.dev:${BOOTSTRAP_GRPC_PORT}
# bootstrap_grpcAddress.scaling.m1=bootstrap-service.bootstrap-service.svc.cluster.local:${BOOTSTRAP_GRPC_PORT}

# bootstrap_httpListenAddress=:${BOOTSTRAP_HTTP_PORT}
# bootstrap_httpListenAddress.dev=localhost:${BOOTSTRAP_HTTP_PORT}


# Miner Service Configuration
# ----------------------------------------
startMiner=true
startMiner.scaling=false
startMiner.testing=false
startMiner.docker.ci.ubsv1.tc1=false
startMiner.docker.ci.ubsv2.tc1=false
startMiner.docker.ci.ubsv3.tc1=false
# startMiner.docker.host.ubsv1=true
# startMiner.docker.host.ubsv2=false
# startMiner.docker.host.ubsv3=false

mine_candidate_request_interval=10
mine_candidate_request_interval.docker.ci.ubsv1.tc1=100

mine_initial_blocks=false
mine_initial_blocks.dev=true
mine_initial_blocks.docker.ci.ubsv1=true
mine_initial_blocks.docker.host.ubsv1=true
mine_initial_blocks.scaling.m1=true
mine_initial_blocks.testing.t1=true
mine_initial_blocks.testing.t2=true
mine_initial_blocks.testing.t3=true

mine_initial_blocks_count=2000
mine_initial_blocks_count.dev=200 # don't need more in dev
mine_initial_blocks_count.dev.simon=200
mine_initial_blocks_count.dev.stu=1000
mine_initial_blocks_count.docker=300
mine_initial_blocks_count.docker.host=3000
mine_initial_blocks_count.dev.liam=1000

mine_initial_blocks_final_wait=5ms

miner_time_mining = true
miner_time_mining.dev.liam = false

miner_waitSeconds.docker=180
miner_waitSeconds.scaling=1800 # 6 miners
miner_waitSeconds.dev.stu=30
miner_waitSeconds.dev.kafka=9

miner_max_subtree_count=650
miner_max_subtree_count_variance=150 # variance should be between 500 and 800

PK1=L56TgyTpDdvL3W24SMoALYotibToSCySQeo4pThLKxw6EFR6f93Q
PK2=KyAwSjuXZNgj78w3W7mR1fVMbPFu2heaCJJkWK5Yy58NZ4xafV6k
PK3=L3NVjmwg3nC7ZPrwMVF6FXiG1a1RZ89nhizmJVctGztRKLYrhtFL
PK4=L3NVjmwg3nC7ZPrwMVF6FXiG1a1RZ89nhizmJVctGztRKLYrhtFL
PK5=L3NVjmwg3nC7ZPrwMVF6FXiG1a1RZ89nhizmJVctGztRKLYrhtFL
PK6=L3NVjmwg3nC7ZPrwMVF6FXiG1a1RZ89nhizmJVctGztRKLYrhtFL

miner_wallet_private_keys=${PK1}
miner_wallet_private_keys.testing=${PK1} | ${PK2} | ${PK3}
miner_wallet_private_keys.scaling=${PK1} | ${PK1} | ${PK1} | ${PK1} | ${PK1} | ${PK1} | ${PK1} | ${PK1} | ${PK1} | ${PK1}
miner_wallet_private_keys.docker=${PK1} | ${PK2} | ${PK3}


miner_httpListenAddress=:${MINER_HTTP_PORT}
miner_httpListenAddress.dev=localhost:${MINER_HTTP_PORT}
miner_httpListenAddress.docker.host.ubsv1=localhost:1${MINER_HTTP_PORT}
miner_httpListenAddress.docker.host.ubsv2=localhost:2${MINER_HTTP_PORT}
miner_httpListenAddress.docker.host.ubsv3=localhost:3${MINER_HTTP_PORT}

coinbase_wallet_private_key=${PK1}
coinbase_wallet_private_key.docker.ci.ubsv1=${PK1}
coinbase_wallet_private_key.docker.ci.ubsv2=${PK2}
coinbase_wallet_private_key.docker.ci.ubsv3=${PK3}
coinbase_wallet_private_key.scaling.m1=${PK1}
coinbase_wallet_private_key.scaling.m2=${PK2}
coinbase_wallet_private_key.scaling.m3=${PK3}
coinbase_wallet_private_key.scaling.m4=${PK4}
coinbase_wallet_private_key.scaling.m5=${PK5}
coinbase_wallet_private_key.scaling.m6=${PK6}
coinbase_wallet_private_key.testing.t1=${PK1}
coinbase_wallet_private_key.testing.t2=${PK2}
coinbase_wallet_private_key.testing.t3=${PK3}

coinbase_arbitrary_text=/teranode/
coinbase_arbitrary_text.dev.siggi=/siggi/
coinbase_arbitrary_text.dev.simon=/simon/
coinbase_arbitrary_text.dev.liam=/liam/
coinbase_arbitrary_text.dev.stu=/stu/
coinbase_arbitrary_text.dev.leonard=/leonard/
coinbase_arbitrary_text.dev.vicente=/vicente/
coinbase_arbitrary_text.dev.gokhan=/gokhan/
coinbase_arbitrary_text.dev.davide=/davide/
coinbase_arbitrary_text.dev.NEW_USER_TEMPLATE=/NEW_USER_TEMPLATE/  # template for future new users (referenced in documentation)
coinbase_arbitrary_text.docker.ci.ubsv1=/m1-eu/
coinbase_arbitrary_text.docker.ci.ubsv2=/m2-us/
coinbase_arbitrary_text.docker.ci.ubsv3=/m3-asia/
coinbase_arbitrary_text.scaling.m1=/m1-eu/
coinbase_arbitrary_text.scaling.m2=/m2-us/
coinbase_arbitrary_text.scaling.m3=/m3-asia/
coinbase_arbitrary_text.scaling.m4=/m4-ane/
coinbase_arbitrary_text.scaling.m5=/m5-cc1/
coinbase_arbitrary_text.scaling.m6=/m6-usw/
coinbase_arbitrary_text.testing.t1=/t1-euc/
coinbase_arbitrary_text.testing.t2=/t2-euc/
coinbase_arbitrary_text.testing.t3=/t3-euc/

peerStatus_timeout=5m

# Asset Service Configuration
# ----------------------------------------
startAsset=true
startAsset.scaling=false
startAsset.testing=false

asset_http_port=80
asset_https_port=443

asset_apiPrefix=/api/v1

asset_grpcListenAddress=:${ASSET_GRPC_PORT}
asset_grpcListenAddress.dev=localhost:${ASSET_GRPC_PORT}
asset_grpcListenAddress.docker.host.ubsv1=localhost:1${ASSET_GRPC_PORT}
asset_grpcListenAddress.docker.host.ubsv2=localhost:2${ASSET_GRPC_PORT}
asset_grpcListenAddress.docker.host.ubsv3=localhost:3${ASSET_GRPC_PORT}

asset_grpcAddress=localhost:${ASSET_GRPC_PORT}
asset_grpcAddress.docker.ci.ubsv1=ubsv-1:${ASSET_GRPC_PORT}
asset_grpcAddress.docker.ci.ubsv2=ubsv-2:${ASSET_GRPC_PORT}
asset_grpcAddress.docker.ci.ubsv3=ubsv-3:${ASSET_GRPC_PORT}
asset_grpcAddress.docker.ci.ubsv3.debug=localhost:${ASSET_GRPC_PORT}
asset_grpcAddress.docker.ci.externaltxblaster.ubsv1=localhost:1${ASSET_GRPC_PORT}
asset_grpcAddress.docker.ci.externaltxblaster.ubsv2=localhost:2${ASSET_GRPC_PORT}
asset_grpcAddress.docker.ci.externaltxblaster.ubsv3=localhost:3${ASSET_GRPC_PORT}
asset_grpcAddress.docker.host.ubsv1=localhost:1${ASSET_GRPC_PORT}
asset_grpcAddress.docker.host.ubsv2=localhost:2${ASSET_GRPC_PORT}
asset_grpcAddress.docker.host.ubsv3=localhost:3${ASSET_GRPC_PORT}
asset_grpcAddress.scaling.m1=k8s:///asset-service1.m1.svc.cluster.local:${ASSET_GRPC_PORT}
asset_grpcAddress.scaling.m2=k8s:///asset-service2.m2.svc.cluster.local:${ASSET_GRPC_PORT}
asset_grpcAddress.scaling.m3=k8s:///asset-service3.m3.svc.cluster.local:${ASSET_GRPC_PORT}
asset_grpcAddress.scaling.m4=k8s:///asset-service4.m4.svc.cluster.local:${ASSET_GRPC_PORT}
asset_grpcAddress.scaling.m5=k8s:///asset-service5.m5.svc.cluster.local:${ASSET_GRPC_PORT}
asset_grpcAddress.scaling.m6=k8s:///asset-service6.m6.svc.cluster.local:${ASSET_GRPC_PORT}
asset_grpcAddress.testing.t1=k8s:///asset-service-t1.t1.svc.cluster.local:${ASSET_GRPC_PORT}
asset_grpcAddress.testing.t2=k8s:///asset-service-t2.t2.svc.cluster.local:${ASSET_GRPC_PORT}
asset_grpcAddress.testing.t3=k8s:///asset-service-t3.t3.svc.cluster.local:${ASSET_GRPC_PORT}

asset_httpListenAddress=:${ASSET_HTTP_PORT}
asset_httpListenAddress.dev=localhost:${ASSET_HTTP_PORT}
asset_httpListenAddress.docker.ci.ubsv3.debug=:3${ASSET_HTTP_PORT}
asset_httpListenAddress.docker.host.ubsv1=localhost:1${ASSET_HTTP_PORT}
asset_httpListenAddress.docker.host.ubsv2=localhost:2${ASSET_HTTP_PORT}
asset_httpListenAddress.docker.host.ubsv3=localhost:3${ASSET_HTTP_PORT}

asset_httpAddress=http://localhost:${ASSET_HTTP_PORT}${asset_apiPrefix}
asset_httpAddress.dev.siggi=http://bastion.ubsv.dev:18090${asset_apiPrefix}
asset_httpAddress.dev.simon=http://bastion.ubsv.dev:18190${asset_apiPrefix}
asset_httpAddress.dev.liam=http://bastion.ubsv.dev:18290${asset_apiPrefix}
asset_httpAddress.dev.stu=http://bastion.ubsv.dev:18390${asset_apiPrefix}
# asset_httpAddress.dev.stu=http://localhost:8090
asset_httpAddress.dev.vicente=http://bastion.ubsv.dev:18490${asset_apiPrefix}
asset_httpAddress.dev.gokhan=http://bastion.ubsv.dev:18590${asset_apiPrefix}
asset_httpAddress.dev.NEW_USER_TEMPLATE=http://bastion.ubsv.dev:18x90 # template for future new users (referenced in documentation)
asset_httpAddress.docker.ci.ubsv1=http://ubsv-1:${ASSET_HTTP_PORT}${asset_apiPrefix}
asset_httpAddress.docker.ci.ubsv2=http://ubsv-2:${ASSET_HTTP_PORT}${asset_apiPrefix}
asset_httpAddress.docker.ci.ubsv3=http://ubsv-3:${ASSET_HTTP_PORT}${asset_apiPrefix}
asset_httpAddress.docker.ci.ubsv1.debug=http://localhost:1${ASSET_HTTP_PORT}${asset_apiPrefix}
asset_httpAddress.docker.ci.ubsv2.debug=http://localhost:2${ASSET_HTTP_PORT}${asset_apiPrefix}
asset_httpAddress.docker.ci.ubsv3.debug=http://localhost:3${ASSET_HTTP_PORT}${asset_apiPrefix}
asset_httpAddress.docker.ci.externaltxblaster.ubsv1=http://localhost:1${ASSET_HTTP_PORT}${asset_apiPrefix}
asset_httpAddress.docker.ci.externaltxblaster.ubsv2=http://localhost:2${ASSET_HTTP_PORT}${asset_apiPrefix}
asset_httpAddress.docker.ci.externaltxblaster.ubsv3=http://localhost:3${ASSET_HTTP_PORT}${asset_apiPrefix}
asset_httpAddress.docker.host.ubsv1=http://localhost:1${ASSET_HTTP_PORT}${asset_apiPrefix}
asset_httpAddress.docker.host.ubsv2=http://localhost:2${ASSET_HTTP_PORT}${asset_apiPrefix}
asset_httpAddress.docker.host.ubsv3=http://localhost:3${ASSET_HTTP_PORT}${asset_apiPrefix}
asset_httpAddress.scaling.m1=http://m1.scaling.ubsv.dev${asset_apiPrefix}
asset_httpAddress.scaling.m2=http://m2.scaling.ubsv.dev${asset_apiPrefix}
asset_httpAddress.scaling.m3=http://m3.scaling.ubsv.dev${asset_apiPrefix}
asset_httpAddress.scaling.m4=http://m4.scaling.ubsv.dev${asset_apiPrefix}
asset_httpAddress.scaling.m5=http://m5.scaling.ubsv.dev${asset_apiPrefix}
asset_httpAddress.scaling.m6=http://m6.scaling.ubsv.dev${asset_apiPrefix}
asset_httpAddress.testing.t1=http://t1.testing.ubsv.dev${asset_apiPrefix}
asset_httpAddress.testing.t2=http://t2.testing.ubsv.dev${asset_apiPrefix}
asset_httpAddress.testing.t3=http://t3.testing.ubsv.dev${asset_apiPrefix}

clientName=Not specified
clientName.dev.siggi=Siggi
clientName.dev.simon=Simon
clientName.dev.liam=Liam
clientName.dev.stu=Stu
clientName.dev.vicente=Vicente
clientName.dev.gokhan=Gokhan
clientName.dev.davide=Davide
clientName.dev.NEW_USER_TEMPLATE=NEW_USER_TEMPLATE # template for future new users (referenced in documentation)
clientName.docker.ci.ubsv1=ubsv-1
clientName.docker.ci.ubsv2=ubsv-2
clientName.docker.ci.ubsv3=ubsv-3
clientName.docker.host=localhost
clientName.scaling.m1=M1
clientName.scaling.m2=M2
clientName.scaling.m3=M3
clientName.scaling.m4=M4
clientName.scaling.m5=M5
clientName.scaling.m6=M6
clientName.testing.t1=T1
clientName.testing.t2=T2
clientName.testing.t3=T3

# turn this on to activate the centrifuge server
asset_centrifugeListenAddress=:${CENTRIFUGE_PORT}
asset_centrifugeListenAddress.dev=localhost:${CENTRIFUGE_PORT}
asset_centrifugeListenAddress.docker.host.ubsv1=localhost:1${CENTRIFUGE_PORT}
asset_centrifugeListenAddress.docker.host.ubsv2=localhost:2${CENTRIFUGE_PORT}
asset_centrifugeListenAddress.docker.host.ubsv3=localhost:3${CENTRIFUGE_PORT}

# Coinbase Tracker Service Configuration
# ----------------------------------------
startCoinbase=true
startCoinbase.docker=true
startCoinbase.scaling=false
startCoinbase.testing=false
startCoinbase.docker.ci.ubsv1.tc1=false
startCoinbase.docker.ci.ubsv2.tc1=false
startCoinbase.docker.ci.ubsv3.tc1=false
startCoinbase.docker.ci.ubsv1.blockassemblyTest=false
startCoinbase.docker.ci.ubsv2.blockassemblyTest=false
startCoinbase.docker.ci.ubsv3.blockassemblyTest=false
startCoinbase.docker.host.ubsv1=true
startCoinbase.docker.host.ubsv2=false
startCoinbase.docker.host.ubsv3=false


coinbase_grpcListenAddress=:${COINBASE_GRPC_PORT}
coinbase_grpcListenAddress.dev=localhost:${COINBASE_GRPC_PORT}
coinbase_grpcListenAddress.docker.ci.externaltxblaster.ubsv1=localhost:${COINBASE_GRPC_PORT}
coinbase_grpcListenAddress.docker.ci.externaltxblaster.ubsv2=localhost:${COINBASE_GRPC_PORT}
coinbase_grpcListenAddress.docker.ci.externaltxblaster.ubsv3=localhost:${COINBASE_GRPC_PORT}
coinbase_grpcListenAddress.docker.host.ubsv1=localhost:1${COINBASE_GRPC_PORT}
coinbase_grpcListenAddress.docker.host.ubsv2=localhost:2${COINBASE_GRPC_PORT}
coinbase_grpcListenAddress.docker.host.ubsv3=localhost:3${COINBASE_GRPC_PORT}

coinbase_assetGrpcAddress=localhost:${ASSET_GRPC_PORT}
coinbase_assetGrpcAddress.docker.ci.ubsv1=ubsv-1:${ASSET_GRPC_PORT}
coinbase_assetGrpcAddress.docker.ci.ubsv2=ubsv-2:${ASSET_GRPC_PORT}
coinbase_assetGrpcAddress.docker.ci.ubsv3=ubsv-3:${ASSET_GRPC_PORT}
coinbase_assetGrpcAddress.docker.ci.ubsv3.debug=localhost:${ASSET_GRPC_PORT}
coinbase_assetGrpcAddress.docker.ci.externaltxblaster.ubsv1=localhost:1${ASSET_GRPC_PORT}
coinbase_assetGrpcAddress.docker.ci.externaltxblaster.ubsv2=localhost:2${ASSET_GRPC_PORT}
coinbase_assetGrpcAddress.docker.ci.externaltxblaster.ubsv3=localhost:3${ASSET_GRPC_PORT}
coinbase_assetGrpcAddress.docker.host.ubsv1=localhost:1${ASSET_GRPC_PORT}
coinbase_assetGrpcAddress.docker.host.ubsv2=localhost:2${ASSET_GRPC_PORT}
coinbase_assetGrpcAddress.docker.host.ubsv3=localhost:3${ASSET_GRPC_PORT}
coinbase_assetGrpcAddress.scaling.m1=k8s:///asset-service1.m1.svc.cluster.local:${ASSET_GRPC_PORT}
coinbase_assetGrpcAddress.scaling.m2=k8s:///asset-service2.m2.svc.cluster.local:${ASSET_GRPC_PORT}
coinbase_assetGrpcAddress.scaling.m3=k8s:///asset-service3.m3.svc.cluster.local:${ASSET_GRPC_PORT}
coinbase_assetGrpcAddress.scaling.m4=k8s:///asset-service4.m4.svc.cluster.local:${ASSET_GRPC_PORT}
coinbase_assetGrpcAddress.scaling.m5=k8s:///asset-service5.m5.svc.cluster.local:${ASSET_GRPC_PORT}
coinbase_assetGrpcAddress.scaling.m6=k8s:///asset-service6.m6.svc.cluster.local:${ASSET_GRPC_PORT}
coinbase_assetGrpcAddress.testing.t1=k8s:///asset-service-t1.t1.svc.cluster.local:${ASSET_GRPC_PORT}
coinbase_assetGrpcAddress.testing.t2=k8s:///asset-service-t2.t2.svc.cluster.local:${ASSET_GRPC_PORT}
coinbase_assetGrpcAddress.testing.t3=k8s:///asset-service-t3.t3.svc.cluster.local:${ASSET_GRPC_PORT}


coinbase_grpcAddress=localhost:${COINBASE_GRPC_PORT}
coinbase_grpcAddress.dev=localhost:${COINBASE_GRPC_PORT}
coinbase_grpcAddress.docker.ci.externaltxblaster.ubsv1=localhost:1${COINBASE_GRPC_PORT}
coinbase_grpcAddress.docker.ci.externaltxblaster.ubsv2=localhost:2${COINBASE_GRPC_PORT}
coinbase_grpcAddress.docker.ci.externaltxblaster.ubsv3=localhost:3${COINBASE_GRPC_PORT}
coinbase_grpcAddress.docker.ci.ubsv1=ubsv-1:${COINBASE_GRPC_PORT}
coinbase_grpcAddress.docker.ci.ubsv2=ubsv-2:${COINBASE_GRPC_PORT}
coinbase_grpcAddress.docker.ci.ubsv3=ubsv-3:${COINBASE_GRPC_PORT}
coinbase_grpcAddress.docker.ci.ubsv3.debug=localhost:${COINBASE_GRPC_PORT}
coinbase_grpcAddress.docker.host.ubsv1=localhost:1${COINBASE_GRPC_PORT}
coinbase_grpcAddress.docker.host.ubsv2=localhost:2${COINBASE_GRPC_PORT}
coinbase_grpcAddress.docker.host.ubsv3=localhost:3${COINBASE_GRPC_PORT}
coinbase_grpcAddress.scaling.m1=k8s:///coinbase-service1.m1.svc.cluster.local:${COINBASE_GRPC_PORT}
coinbase_grpcAddress.scaling.m2=k8s:///coinbase-service2.m2.svc.cluster.local:${COINBASE_GRPC_PORT}
coinbase_grpcAddress.scaling.m3=k8s:///coinbase-service3.m3.svc.cluster.local:${COINBASE_GRPC_PORT}
coinbase_grpcAddress.scaling.m4=k8s:///coinbase-service4.m4.svc.cluster.local:${COINBASE_GRPC_PORT}
coinbase_grpcAddress.scaling.m5=k8s:///coinbase-service5.m5.svc.cluster.local:${COINBASE_GRPC_PORT}
coinbase_grpcAddress.scaling.m6=k8s:///coinbase-service6.m6.svc.cluster.local:${COINBASE_GRPC_PORT}
coinbase_grpcAddress.testing.t1=k8s:///coinbase-service-t1.t1.svc.cluster.local:${COINBASE_GRPC_PORT}
coinbase_grpcAddress.testing.t2=k8s:///coinbase-service-t2.t2.svc.cluster.local:${COINBASE_GRPC_PORT}
coinbase_grpcAddress.testing.t3=k8s:///coinbase-service-t3.t3.svc.cluster.local:${COINBASE_GRPC_PORT}

coinbase_notification_threshold.dev.stu=100000
coinbase_notification_threshold.scaling=100000
coinbase_notification_threshold.testing=100000

coinbase_store_dbTimeoutMillis=5000

coinbase_store=sqlite:///coinbase
coinbase_store.dev.stu=postgres://ubsv:ubsv@localhost:5432/coinbase
coinbase_store.dev.simon=postgres://ubsv:ubsv@localhost:5432/coinbase
coinbase_store.dev.liam=postgres://ubsv:ubsv@localhost:5432/coinbase
coinbase_store.docker=postgres://coinbase:coinbase@postgres:5432/coinbase
coinbase_store.docker.ci.externaltxblaster=postgres://coinbase:coinbase@postgres:5432/coinbase
coinbase_store.docker.ci.externaltxblaster.ubsv1=postgres://coinbase1:coinbase1@localhost:5432/coinbase1
coinbase_store.docker.ci.externaltxblaster.ubsv2=postgres://coinbase2:coinbase2@localhost:5432/coinbase2
coinbase_store.docker.ci.externaltxblaster.ubsv3=postgres://coinbase3:coinbase3@localhost:5432/coinbase3
coinbase_store.docker.ci.chainintegrity.ubsv1=postgres://coinbase1:coinbase1@localhost:5432/coinbase1
coinbase_store.docker.ci.chainintegrity.ubsv2=postgres://coinbase2:coinbase2@localhost:5432/coinbase2
coinbase_store.docker.ci.chainintegrity.ubsv3=postgres://coinbase3:coinbase3@localhost:5432/coinbase3
coinbase_store.docker.ci.ubsv3.debug=postgres://coinbase3:coinbase3@localhost:5432/coinbase3
coinbase_store.docker.host.ubsv1=postgres://coinbase1:coinbase1@localhost:15432/coinbase1
coinbase_store.docker.host.ubsv2=postgres://coinbase2:coinbase2@localhost:15432/coinbase2
coinbase_store.docker.host.ubsv3=postgres://coinbase3:coinbase3@localhost:15432/coinbase3











# coinbase are shared on the same server




coinbase_wait_for_peers=true
coinbase_wait_for_peers.dev.kafka=false
coinbase_wait_for_peers.scaling=false
coinbase_wait_for_peers.testing=false

# Faucet Service Configuration
# ----------------------------------------
startFaucet=true
startFaucet.scaling=false
startFaucet.testing=false
startFaucet.docker.ci=false

faucet_httpListenAddress=:${FAUCET_HTTP_PORT}
faucet_httpListenAddress.dev=localhost:${FAUCET_HTTP_PORT}
faucet_httpListenAddress.docker.host.ubsv1=localhost:1${FAUCET_HTTP_PORT}
faucet_httpListenAddress.docker.host.ubsv2=localhost:2${FAUCET_HTTP_PORT}
faucet_httpListenAddress.docker.host.ubsv3=localhost:3${FAUCET_HTTP_PORT}

# Legacy Service Configuration
# ----------------------------------------
startLegacy=false

legacy_workingDir=data/legacy

legacy_httpListenAddress=:${LEGACY_HTTP_PORT}
legacy_httpListenAddress.dev=localhost:${LEGACY_HTTP_PORT}
legacy_httpListenAddress.docker.host.ubsv1=localhost:1${LEGACY_HTTP_PORT}
legacy_httpListenAddress.docker.host.ubsv2=localhost:2${LEGACY_HTTP_PORT}
legacy_httpListenAddress.docker.host.ubsv3=localhost:3${LEGACY_HTTP_PORT}

legacy_httpAddress=http://localhost:${LEGACY_HTTP_PORT}
legacy_httpAddress.docker.ci.ubsv1=http://ubsv-1:${LEGACY_HTTP_PORT}
legacy_httpAddress.docker.ci.ubsv2=http://ubsv-2:${LEGACY_HTTP_PORT}
legacy_httpAddress.docker.ci.ubsv3=http://ubsv-3:${LEGACY_HTTP_PORT}
legacy_httpAddress.docker.ci.ubsv3.debug=http://localhost:${LEGACY_HTTP_PORT}
legacy_httpAddress.docker.host.ubsv1=http://localhost:1${LEGACY_HTTP_PORT}
legacy_httpAddress.docker.host.ubsv2=http://localhost:2${LEGACY_HTTP_PORT}
legacy_httpAddress.docker.host.ubsv3=http://localhost:3${LEGACY_HTTP_PORT}
legacy_httpAddress.scaling.m1=http://legacy-service1.m1.svc.cluster.local:${LEGACY_HTTP_PORT}
legacy_httpAddress.scaling.m2=http://legacy-service2.m2.svc.cluster.local:${LEGACY_HTTP_PORT}
legacy_httpAddress.scaling.m3=http://legacy-service3.m3.svc.cluster.local:${LEGACY_HTTP_PORT}
legacy_httpAddress.scaling.m4=http://legacy-service4.m4.svc.cluster.local:${LEGACY_HTTP_PORT}
legacy_httpAddress.scaling.m5=http://legacy-service5.m5.svc.cluster.local:${LEGACY_HTTP_PORT}
legacy_httpAddress.scaling.m6=http://legacy-service6.m6.svc.cluster.local:${LEGACY_HTTP_PORT}
legacy_httpAddress.testing.t1=http://legacy-service-t1.t1.svc.cluster.local:${LEGACY_HTTP_PORT}
legacy_httpAddress.testing.t2=http://legacy-service-t2.t2.svc.cluster.local:${LEGACY_HTTP_PORT}
legacy_httpAddress.testing.t3=http://legacy-service-t3.t3.svc.cluster.local:${LEGACY_HTTP_PORT}

legacy_connect_peers.dev.legacy=172.31.11.45:8333 | 172.31.11.78:8333


# P2P Configuration
# ----------------------------------------
startP2P=true
startP2P.scaling=false
startP2P.testing=false
startP2P.docker.ci.ubsv2.tc3=false

p2p_ip=0.0.0.0
p2p_ip.dev=127.0.0.1

p2p_port=${P2P_PORT}
p2p_port.docker.host.ubsv1=1${P2P_PORT}
p2p_port.docker.host.ubsv2=2${P2P_PORT}
p2p_port.docker.host.ubsv3=3${P2P_PORT}
p2p_port_coinbase=${P2P_PORT}
#dev env runs in same process so must have different port
p2p_port_coinbase.dev=${P2P_PORT_COINBASE}
p2p_port_coinbase.docker=${P2P_PORT_COINBASE}
p2p_port_coinbase.docker.host.ubsv1=1${P2P_PORT_COINBASE}
p2p_port_coinbase.docker.host.ubsv2=2${P2P_PORT_COINBASE}
p2p_port_coinbase.docker.host.ubsv3=3${P2P_PORT_COINBASE}

p2p_optimise_retries=false

p2p_topic_prefix=github.com/bitcoin-sv/ubsv
p2p_topic_prefix.dev=dev.github.com/bitcoin-sv/ubsv
p2p_topic_prefix.dev.simon=dev.simon.github.com/bitcoin-sv/ubsv
p2p_topic_prefix.scaling=scaling.github.com/bitcoin-sv/ubsv
p2p_topic_prefix.testing=testing.github.com/bitcoin-sv/ubsv

p2p_block_topic=block
p2p_subtree_topic=subtree
p2p_bestblock_topic=bestblock
p2p_mining_on_topic=miningon
# The P2P topic to publish rejected transaction messages
p2p_rejected_tx_topic=rejected_tx

p2p_httpListenAddress=:${P2P_HTTP_PORT}
p2p_httpListenAddress.dev=localhost:${P2P_HTTP_PORT}
p2p_httpListenAddress.docker=localhost:${P2P_HTTP_PORT}
p2p_httpListenAddress.docker.host.ubsv1=localhost:1${P2P_HTTP_PORT}
p2p_httpListenAddress.docker.host.ubsv2=localhost:2${P2P_HTTP_PORT}
p2p_httpListenAddress.docker.host.ubsv3=localhost:3${P2P_HTTP_PORT}

p2p_httpAddress=localhost:${P2P_HTTP_PORT}
p2p_httpAddress.dev=localhost:${P2P_HTTP_PORT}
p2p_httpAddress.scaling.m1=p2p-service1.m1.svc.cluster.local:${P2P_HTTP_PORT}
p2p_httpAddress.scaling.m2=p2p-service2.m2.svc.cluster.local:${P2P_HTTP_PORT}
p2p_httpAddress.scaling.m3=p2p-service3.m3.svc.cluster.local:${P2P_HTTP_PORT}
p2p_httpAddress.scaling.m4=p2p-service4.m4.svc.cluster.local:${P2P_HTTP_PORT}
p2p_httpAddress.scaling.m5=p2p-service5.m5.svc.cluster.local:${P2P_HTTP_PORT}
p2p_httpAddress.scaling.m6=p2p-service6.m6.svc.cluster.local:${P2P_HTTP_PORT}
p2p_httpAddress.testing.t1=p2p-service-t1.t1.svc.cluster.local:${P2P_HTTP_PORT}
p2p_httpAddress.testing.t2=p2p-service-t2.t2.svc.cluster.local:${P2P_HTTP_PORT}
p2p_httpAddress.testing.t3=p2p-service-t3.t3.svc.cluster.local:${P2P_HTTP_PORT}
p2p_httpAddress.docker.host.ubsv1=localhost:1${P2P_HTTP_PORT}
p2p_httpAddress.docker.host.ubsv2=localhost:2${P2P_HTTP_PORT}
p2p_httpAddress.docker.host.ubsv3=localhost:3${P2P_HTTP_PORT}

p2p_dht_use_private=false
p2p_dht_use_private.dev=true
p2p_dht_use_private.docker=true
p2p_dht_use_private.scaling=true
p2p_dht_use_private.testing=true

p2p_dht_protocol_id=/ubsv

p2p_shared_key=285b49e6d910726a70f205086c39cbac6d8dcc47839053a21b1f614773bbc137

# create your own private key and peer ID using cmd/keygen
p2p_private_key.dev=90de404ee469fb284feb6ba93b429b95d7e0eb1c5ff530dc06a50cf268c72683ac3db1b6c7527b9b853e72647e760798125441f7490353a01a6b7e056df843d0
p2p_peer_id.dev=12D3KooWMQira6uh4rptNzMP5sojTdNXyveAWMKJi5ySoepVXGxo

p2p_private_key.docker.ci.ubsv1=c8a1b91ae120878d91a04c904e0d565aa44b2575c1bb30a729bd3e36e2a1d5e6067216fa92b1a1a7e30d0aaabe288e25f1efc0830f309152638b61d84be6b71d
p2p_peer_id.docker.ci.ubsv1=12D3KooWAFXWuxgdJoRsaA4J4RRRr8yu6WCrAPf8FaS7UfZg3ceG
p2p_private_key.docker.ci.ubsv2=89a2d8acf5b2e60fd969914c326c63cde50675a47897c0eaacc02eb6ff8665585d4d059f977910472bcb75040617632019cc0749443fdc66d331b61c8cfb4b0f
p2p_peer_id.docker.ci.ubsv2=12D3KooWG6aCkDmi5tqx4G4AvVDTQdSVvTSzzQvk1vh9CtSR8KEW
p2p_private_key.docker.ci.ubsv3=d77a7cac7833f2c0263ed7b9aaeb8dda1effaf8af948d570ed8f7a93bd3c418d6efee7bdd82ddb80484be84ba0c78ea07251a3ba2b45b2b3367fd5e2f0284e7c
p2p_peer_id.docker.ci.ubsv3=12D3KooWHHeTM3aK4s9DKS6DQ7SbBb7czNyJsPZtQiUKa4fduMB9
p2p_private_key.docker.host.ubsv1=c8a1b91ae120878d91a04c904e0d565aa44b2575c1bb30a729bd3e36e2a1d5e6067216fa92b1a1a7e30d0aaabe288e25f1efc0830f309152638b61d84be6b71d
p2p_peer_id.docker.host.ubsv1=12D3KooWAFXWuxgdJoRsaA4J4RRRr8yu6WCrAPf8FaS7UfZg3ceG
p2p_private_key.docker.host.ubsv2=89a2d8acf5b2e60fd969914c326c63cde50675a47897c0eaacc02eb6ff8665585d4d059f977910472bcb75040617632019cc0749443fdc66d331b61c8cfb4b0f
p2p_peer_id.docker.host.ubsv2=12D3KooWG6aCkDmi5tqx4G4AvVDTQdSVvTSzzQvk1vh9CtSR8KEW
p2p_private_key.docker.host.ubsv3=d77a7cac7833f2c0263ed7b9aaeb8dda1effaf8af948d570ed8f7a93bd3c418d6efee7bdd82ddb80484be84ba0c78ea07251a3ba2b45b2b3367fd5e2f0284e7c
p2p_peer_id.docker.host.ubsv3=12D3KooWHHeTM3aK4s9DKS6DQ7SbBb7czNyJsPZtQiUKa4fduMB9


p2p_private_key.scaling.m1=97f0144e36f55a9aa1a8e4f8a49a417c9552fc3a224dcd785e1704cab714290c5884158964322bf79698dce9f8089f7e2e78d10afe597d7fe18e0b4328dd823f
p2p_private_key.scaling.m2=bc68e5570105978ef622544be8c02e00f773a8248955be03ac65b0b4fde48ed8f647cbeb6ac81a3e996231e45b16ee413838f633f90c61fcb7b44f2b15b17818
p2p_private_key.scaling.m3=4152ea22c2152ae4ae662809331cf4e05efecef970a000961016cd7a7cbcda52efc79dd47f78dc8de72ee9d055156a1d7a9b4c84d90fe61398fb3395e2b52d16
p2p_private_key.scaling.m4=fe7e0ae1c9a13ddc1e72b2b478e099eca87c1782f1e2af2b662c9b1cb1db8f25b65ae14a0387479658f5034cd0f2c000e2b1cecb98d899fc15570ee29b30cd69
p2p_private_key.scaling.m5=6febeeceae316d0c7330f1ff47108391cef23e28d9cb09aa74d2d93c449be688cd37f7f276c68c3eb6063d2f75083c9b467f1a0407196cb7779bf092073032e1
p2p_private_key.scaling.m6=5e08423f6db13b5150614d161f0ccda802fb6373b1193d7d2f405a7e49e9c7496ebe450f86db96eae79cb14cd739d15e357b04bd7a30a60dd154086d59ee69de
# testing using same as private. is this ok?
p2p_private_key.testing.t1=97f0144e36f55a9aa1a8e4f8a49a417c9552fc3a224dcd785e1704cab714290c5884158964322bf79698dce9f8089f7e2e78d10afe597d7fe18e0b4328dd823f
p2p_private_key.testing.t2=bc68e5570105978ef622544be8c02e00f773a8248955be03ac65b0b4fde48ed8f647cbeb6ac81a3e996231e45b16ee413838f633f90c61fcb7b44f2b15b17818
p2p_private_key.testing.t3=4152ea22c2152ae4ae662809331cf4e05efecef970a000961016cd7a7cbcda52efc79dd47f78dc8de72ee9d055156a1d7a9b4c84d90fe61398fb3395e2b52d16

M1_P2P_ID=12D3KooWFmtrxJsWUQo3axbyUAqXMH33G9HXmd3xaW3XuhsKccLn
M2_P2P_ID=12D3KooWSPjxch3frXkbq612xz7Xbs7y1w47hvLieDt7r3mRE43q
M3_P2P_ID=12D3KooWRxN9gLTfVZXLGBYLrijar3bkstXWpo2HMY23JLFpXDfj
M4_P2P_ID=12D3KooWN6Ck8yddcRCuZa6B2Ti5noUsv6Tb5Q2LVk9KQ6nF46oJ
M5_P2P_ID=12D3KooWPdTFCqbUWEddkpuwToFAXCpU5ZhNYn8n6tSXbWqAK7G4
M6_P2P_ID=12D3KooWHGfHqZ2PgBmcSxwdWGjtS8E6Yvy9nzMpFbnX1Attfmws
# testing reusing scaling IDs
T1_P2P_ID=12D3KooWFmtrxJsWUQo3axbyUAqXMH33G9HXmd3xaW3XuhsKccLn
T2_P2P_ID=12D3KooWSPjxch3frXkbq612xz7Xbs7y1w47hvLieDt7r3mRE43q
T3_P2P_ID=12D3KooWRxN9gLTfVZXLGBYLrijar3bkstXWpo2HMY23JLFpXDfj

p2p_peer_id.scaling.m1=${M1_P2P_ID}
p2p_peer_id.scaling.m2=${M2_P2P_ID}
p2p_peer_id.scaling.m3=${M3_P2P_ID}
p2p_peer_id.scaling.m4=${M4_P2P_ID}
p2p_peer_id.scaling.m5=${M5_P2P_ID}
p2p_peer_id.scaling.m6=${M6_P2P_ID}
p2p_peer_id.testing.t1=${T1_P2P_ID}
p2p_peer_id.testing.t2=${T2_P2P_ID}
p2p_peer_id.testing.t3=${T3_P2P_ID}

# p2p_static_peers is optional, the node will use the bootstrap addresses to find peers regardless
p2p_static_peers=
p2p_static_peers.docker.ci.ubsv1=/dns/ubsv-2/tcp/${P2P_PORT}/p2p/12D3KooWG6aCkDmi5tqx4G4AvVDTQdSVvTSzzQvk1vh9CtSR8KEW|/dns/ubsv-3/tcp/${P2P_PORT}/p2p/12D3KooWHHeTM3aK4s9DKS6DQ7SbBb7czNyJsPZtQiUKa4fduMB9
p2p_static_peers.docker.ci.ubsv2=/dns/ubsv-1/tcp/${P2P_PORT}/p2p/12D3KooWAFXWuxgdJoRsaA4J4RRRr8yu6WCrAPf8FaS7UfZg3ceG|/dns/ubsv-3/tcp/${P2P_PORT}/p2p/12D3KooWHHeTM3aK4s9DKS6DQ7SbBb7czNyJsPZtQiUKa4fduMB9
p2p_static_peers.docker.ci.ubsv3=/dns/ubsv-1/tcp/${P2P_PORT}/p2p/12D3KooWAFXWuxgdJoRsaA4J4RRRr8yu6WCrAPf8FaS7UfZg3ceG|/dns/ubsv-2/tcp/${P2P_PORT}/p2p/12D3KooWG6aCkDmi5tqx4G4AvVDTQdSVvTSzzQvk1vh9CtSR8KEW

p2p_static_peers.docker.ci.ubsv1.debug=
# p2p_static_peers.docker.ci.ubsv2.debug=/dns/ubsv-1/tcp/${P2P_PORT}/p2p/12D3KooWAFXWuxgdJoRsaA4J4RRRr8yu6WCrAPf8FaS7UfZg3ceG
p2p_static_peers.docker.ci.ubsv3.debug=/dns/localhost/tcp/1${P2P_PORT}/p2p/12D3KooWAFXWuxgdJoRsaA4J4RRRr8yu6WCrAPf8FaS7UfZg3ceG|/dns/localhost/tcp/2${P2P_PORT}/p2p/12D3KooWG6aCkDmi5tqx4G4AvVDTQdSVvTSzzQvk1vh9CtSR8KEW

p2p_static_peers.docker.host.ubsv1=/dns/localhost/tcp/2${P2P_PORT}/p2p/12D3KooWG6aCkDmi5tqx4G4AvVDTQdSVvTSzzQvk1vh9CtSR8KEW|/dns/localhost/tcp/3${P2P_PORT}/p2p/12D3KooWHHeTM3aK4s9DKS6DQ7SbBb7czNyJsPZtQiUKa4fduMB9
p2p_static_peers.docker.host.ubsv2=/dns/localhost/tcp/1${P2P_PORT}/p2p/12D3KooWAFXWuxgdJoRsaA4J4RRRr8yu6WCrAPf8FaS7UfZg3ceG|/dns/localhost/tcp/3${P2P_PORT}/p2p/12D3KooWHHeTM3aK4s9DKS6DQ7SbBb7czNyJsPZtQiUKa4fduMB9
p2p_static_peers.docker.host.ubsv3=/dns/localhost/tcp/1${P2P_PORT}/p2p/12D3KooWAFXWuxgdJoRsaA4J4RRRr8yu6WCrAPf8FaS7UfZg3ceG|/dns/localhost/tcp/2${P2P_PORT}/p2p/12D3KooWG6aCkDmi5tqx4G4AvVDTQdSVvTSzzQvk1vh9CtSR8KEW

M1_P2P=/dns/m1.scaling.ubsv.dev/tcp/${P2P_PORT}/p2p/${M1_P2P_ID}
M2_P2P=/dns/m2.scaling.ubsv.dev/tcp/${P2P_PORT}/p2p/${M2_P2P_ID}
M3_P2P=/dns/m3.scaling.ubsv.dev/tcp/${P2P_PORT}/p2p/${M3_P2P_ID}
M4_P2P=/dns/m4.scaling.ubsv.dev/tcp/${P2P_PORT}/p2p/${M4_P2P_ID}
M5_P2P=/dns/m5.scaling.ubsv.dev/tcp/${P2P_PORT}/p2p/${M5_P2P_ID}
M6_P2P=/dns/m6.scaling.ubsv.dev/tcp/${P2P_PORT}/p2p/${M6_P2P_ID}
T1_P2P=/dns/t1.testing.ubsv.dev/tcp/${P2P_PORT}/p2p/${T1_P2P_ID}
T2_P2P=/dns/t2.testing.ubsv.dev/tcp/${P2P_PORT}/p2p/${T2_P2P_ID}
T3_P2P=/dns/t3.testing.ubsv.dev/tcp/${P2P_PORT}/p2p/${T3_P2P_ID}

p2p_static_peers.scaling.m1=${M2_P2P}|${M3_P2P}|${M4_P2P}|${M5_P2P}|${M6_P2P}
p2p_static_peers.scaling.m2=${M1_P2P}|${M3_P2P}|${M4_P2P}|${M5_P2P}|${M6_P2P}
p2p_static_peers.scaling.m3=${M1_P2P}|${M2_P2P}|${M4_P2P}|${M5_P2P}|${M6_P2P}
p2p_static_peers.scaling.m4=${M1_P2P}|${M2_P2P}|${M3_P2P}|${M5_P2P}|${M6_P2P}
p2p_static_peers.scaling.m5=${M1_P2P}|${M2_P2P}|${M3_P2P}|${M4_P2P}|${M6_P2P}
p2p_static_peers.scaling.m6=${M1_P2P}|${M2_P2P}|${M3_P2P}|${M4_P2P}|${M5_P2P}
p2p_static_peers.testing.t1=${T2_P2P}|${T3_P2P}
p2p_static_peers.testing.t2=${T1_P2P}|${T3_P2P}
p2p_static_peers.testing.t3=${T1_P2P}|${T2_P2P}

p2p_bootstrapAddresses=/dns4/eu-p2pbootstrap.ubsv.dev/tcp/${P2P_BOOTSTRAP_PORT}/p2p/12D3KooWESmhNAN8s6NPdGNvJH3zJ4wMKDxapXKNUe2DzkAwKYqK|/dns4/us-p2pbootstrap.ubsv.dev/tcp/${P2P_BOOTSTRAP_PORT}/p2p/12D3KooWJ6kQHAR65xkA34NABsNVAJyVxPWh8JUSo1vtZsTyw4GD
# p2p_bootstrapAddresses.docker=/dns4/p2p-bootstrap-1/tcp/${P2P_BOOTSTRAP_PORT}/p2p/12D3KooWS43tBXaGewmskvL1B82KccLP5JafTvreiJNbHCbZhDnh
# p2p_bootstrapAddresses.docker.ci.ubsv3.debug=/dns4/127.0.0.1/tcp/1${P2P_BOOTSTRAP_PORT}/p2p/12D3KooWS43tBXaGewmskvL1B82KccLP5JafTvreiJNbHCbZhDnh


coinbase_p2p_private_key.dev=44a5a189fbad1d7bc0c59b33fbd5e485f2f4d3d8bf293838c56ce72e53b557171444c0bb7d5cf75112717084cee9e9e98651421b3cd29d721e43c0a51d81aa54
coinbase_p2p_peer_id.dev=12D3KooWBBV8PL949p46DJHwJkjESoPGCYhqHv1Ek1DkbQ6HGB8X

coinbase_p2p_private_key.docker.ci.ubsv1=e76c77795b43d2aacd564648bffebde74a4c31540357dad4a3694a561b4c4f1fbb0ba060a3015f7f367742500ef8486707e58032af1b4dfdb1203c790bcf2526
coinbase_p2p_peer_id.docker.ci.ubsv1=12D3KooWNQWh27xAsZRuXzANGQjLVJqXGVdp1errjLfc3wWvawZw
coinbase_p2p_private_key.docker.ci.ubsv2=860616e0492a3050aa760440469acfe4f57cf5387a765f5227603c4f6aeac985bf6643d453a1d68a101e52766e9feb9721b95e34aa73e5ea6c69a44be43cab6d
coinbase_p2p_peer_id.docker.ci.ubsv2=12D3KooWNhWUxABRjenSeCT3V4zVKnPqfSA3jvXQnPbVmcp1ZtYU
coinbase_p2p_private_key.docker.ci.ubsv3=1d6a9c8963fdbb86eabc4d10cb1efdf418197cfc3f9779e3c8229663411ae5c8f1cee260eeeae89cb45aae6955230557eba5bf63ef38087ec6be91ab744326c7
coinbase_p2p_peer_id.docker.ci.ubsv3=12D3KooWS6HPmwhqSDdS78rLqUQpM39Jf59XYGxJNE77W4WziGL6

coinbase_p2p_private_key.docker.host.ubsv1=e76c77795b43d2aacd564648bffebde74a4c31540357dad4a3694a561b4c4f1fbb0ba060a3015f7f367742500ef8486707e58032af1b4dfdb1203c790bcf2526
coinbase_p2p_peer_id.docker.host.ubsv1=12D3KooWNQWh27xAsZRuXzANGQjLVJqXGVdp1errjLfc3wWvawZw
coinbase_p2p_private_key.docker.host.ubsv2=860616e0492a3050aa760440469acfe4f57cf5387a765f5227603c4f6aeac985bf6643d453a1d68a101e52766e9feb9721b95e34aa73e5ea6c69a44be43cab6d
coinbase_p2p_peer_id.docker.host.ubsv2=12D3KooWNhWUxABRjenSeCT3V4zVKnPqfSA3jvXQnPbVmcp1ZtYU
coinbase_p2p_private_key.docker.host.ubsv3=1d6a9c8963fdbb86eabc4d10cb1efdf418197cfc3f9779e3c8229663411ae5c8f1cee260eeeae89cb45aae6955230557eba5bf63ef38087ec6be91ab744326c7
coinbase_p2p_peer_id.docker.host.ubsv3=12D3KooWS6HPmwhqSDdS78rLqUQpM39Jf59XYGxJNE77W4WziGL6

coinbase_p2p_private_key.scaling.m1=8b0681bab86242bc1d76c94ad44db783009414c564286b0108ce0e03a8fcc7d39e272e8bbc72dde3411386a3c0111b3e14c7bc37dd5b76f3c843ec5e7ad7546a
coinbase_p2p_peer_id.scaling.m1=12D3KooWLTjEjjK323Wj48QreWQ729mPcS9mpX2jNCfG4SN5n8nM
coinbase_p2p_private_key.scaling.m2=8e5f7dad838fe46138f43e0f3cf2dab46693efd07b92e2897d486e987528f22925e3c2d8a842c3dc0432525373d982f10eb1b471381a3b6dead51df3d28d60f2
coinbase_p2p_peer_id.scaling.m2=12D3KooWCNGgnN3ZoZ4ZJg7i1tmYiisKdMhxUYTmYnFKP6XPPoxu
coinbase_p2p_private_key.scaling.m3=b233925e84dafe385cf5dadc27d70f3d2672580ba48db42cb937d54b212dde1d06573681bea355b305ea79843782dddfa316875ae054950d8822d8b0cbbe39e0
coinbase_p2p_peer_id.scaling.m3=12D3KooWAF7kFdATDwtFgsoKep7obFFLjjodS7YdFUSErK7ZSoSP
coinbase_p2p_private_key.scaling.m4=ebf5d29d076b3f9dbaab80b9535f1dfd7dfab579fdbed36cf2944e3073575dc29636f9d285dd5738b3b21eb5e49f19b4128fe888f38fd63d3a51abac47bb5a65
coinbase_p2p_peer_id.scaling.m4=12D3KooWKvjwjFesTV7PgNJ928JENGgfvhFXV4FCkVnPHzsYye5S
coinbase_p2p_private_key.scaling.m5=953a0f178eda5847362eab86b90b794d720c261cf1218f1e2015e9af62f336d05026757c0e9c52821380561053e65e3b325886adbe7a2fb4e1a61c70dffa7db7
coinbase_p2p_peer_id.scaling.m5=12D3KooWFDEoEPHTybXRt5FvjfxmdT8UQ94xygvX1TVptzcg2gTY
coinbase_p2p_private_key.scaling.m6=ce49a558c46012d4aaaacea957839be4fdd3298ad9c7bdd7a83d6b48aed0b58fa735cc746ff78e02f2009669457a63074d3d188abed260f718b3c9d6a81e580a
coinbase_p2p_peer_id.scaling.m6=12D3KooWM55qLHkPW4qpQa5P44mWbgi9fGa9QzUdvx25aqAzyu2H
coinbase_p2p_private_key.testing.t1=8b0681bab86242bc1d76c94ad44db783009414c564286b0108ce0e03a8fcc7d39e272e8bbc72dde3411386a3c0111b3e14c7bc37dd5b76f3c843ec5e7ad7546a
coinbase_p2p_peer_id.testing.t1=12D3KooWLTjEjjK323Wj48QreWQ729mPcS9mpX2jNCfG4SN5n8nM
coinbase_p2p_private_key.testing.t2=8e5f7dad838fe46138f43e0f3cf2dab46693efd07b92e2897d486e987528f22925e3c2d8a842c3dc0432525373d982f10eb1b471381a3b6dead51df3d28d60f2
coinbase_p2p_peer_id.testing.t2=12D3KooWCNGgnN3ZoZ4ZJg7i1tmYiisKdMhxUYTmYnFKP6XPPoxu
coinbase_p2p_private_key.testing.t3=b233925e84dafe385cf5dadc27d70f3d2672580ba48db42cb937d54b212dde1d06573681bea355b305ea79843782dddfa316875ae054950d8822d8b0cbbe39e0
coinbase_p2p_peer_id.testing.t3=12D3KooWAF7kFdATDwtFgsoKep7obFFLjjodS7YdFUSErK7ZSoSP


coinbase_p2p_static_peers.dev=/ip4/127.0.0.1/tcp/${P2P_PORT}/p2p/12D3KooWMQira6uh4rptNzMP5sojTdNXyveAWMKJi5ySoepVXGxo
coinbase_p2p_static_peers.docker=/dns/ubsv-1/tcp/${P2P_PORT}/p2p/12D3KooWAFXWuxgdJoRsaA4J4RRRr8yu6WCrAPf8FaS7UfZg3ceG|/dns/ubsv-2/tcp/${P2P_PORT}/p2p/12D3KooWG6aCkDmi5tqx4G4AvVDTQdSVvTSzzQvk1vh9CtSR8KEW|/dns/ubsv-3/tcp/${P2P_PORT}/p2p/12D3KooWHHeTM3aK4s9DKS6DQ7SbBb7czNyJsPZtQiUKa4fduMB9
coinbase_p2p_static_peers.docker.ci.ubsv1.debug=
coinbase_p2p_static_peers.docker.ci.ubsv2.debug=
coinbase_p2p_static_peers.docker.ci.ubsv3.debug=
coinbase_p2p_static_peers.docker.host=/dns/localhost/tcp/1${P2P_PORT}/p2p/12D3KooWAFXWuxgdJoRsaA4J4RRRr8yu6WCrAPf8FaS7UfZg3ceG|/dns/localhost/tcp/2${P2P_PORT}/p2p/12D3KooWG6aCkDmi5tqx4G4AvVDTQdSVvTSzzQvk1vh9CtSR8KEW|/dns/localhost/tcp/3${P2P_PORT}/p2p/12D3KooWHHeTM3aK4s9DKS6DQ7SbBb7czNyJsPZtQiUKa4fduMB9
coinbase_p2p_static_peers.scaling=${M1_P2P}|${M2_P2P}|${M3_P2P}|${M4_P2P}|${M5_P2P}|${M6_P2P}
coinbase_p2p_static_peers.testing=${T1_P2P}|${T2_P2P}|${T3_P2P}

tx_blaster_p2p_private_key=f19576f6a8ea51ebf5a1fb05cdfea7b66bfa8ecdcec58232d064f3343fb19ab29d99c9e7339b479ed4ee48d7bb7a078bcc9e2ad2355e7e6ba94297e97ecb7744
tx_blaster_p2p_peer_id=12D3KooWLRaBuYhHPcj8ixqwiVLtJ6YxMMSJRDwPYKVN5HWSnUWo

tx_blaster_p2p_private_key.scaling.m1=c46672a8343179958b9bc76a0a4079e5ffbfc64aa89316d944b2316bd2e65582171333b40da75e31d23d76c231d67762a9031dcb0cbe725e2114599900b7b125
tx_blaster_p2p_peer_id.scaling.m1=12D3KooWBNSXb2x1tUjpofMXckHwmATVGD9kYRT5reBCJEnxXVUQ
tx_blaster_p2p_private_key.scaling.m2=74473a119f9adc5b49c0ccd9974c687974ab0ecd0f9330f4d14b3f16fb8c7be71c7d662fef5bc33de42257940a0f79f276e03e06a6f584b178b82d700f49e15e
tx_blaster_p2p_peer_id.scaling.m2=12D3KooWBjaVFuwk7S2KHKjnoHNembb6DQDkrumoG24idHKXi7Jd
tx_blaster_p2p_private_key.scaling.m3=f0728085429c185ce0b4bcbe48f0b912f5f87464e2ac15a5358900d3e14b5486bf3f9463df2abea9c198d3376b1066be16738f8cd8447fd303802cf82531c6fe
tx_blaster_p2p_peer_id.scaling.m3=12D3KooWNgvGZztjDqJQmCTH5fSap2vpfm6XKgWTg1sdyaVWm1RX
tx_blaster_p2p_private_key.scaling.m4=503341a408e245743da6df4dbf2e22d1c28bfe0d56a23151da17169225e0cc32fa436e5a4a849293c667863fb876025631a87ab87041037d65941dd4866cd764
tx_blaster_p2p_peer_id.scaling.m4=12D3KooWSfHjGiZRG9CS8q9ojTmQTfSFP2KW3bnZZjbfiX6J8MFZ
tx_blaster_p2p_private_key.scaling.m5=ce29af2fa4eb174ea6612cbc7d3bd354e7afea8622c385e84e7a68a5238273ad25f69ac977c9400fb1e4444f1b81c7e21aac680eb3f36a7278a56a5d6cd40db0
tx_blaster_p2p_peer_id.scaling.m5=12D3KooWCNZMNSeqB6a3NqhvEqrsc6zUABEQFMvAvnsQr7UmBm2P
tx_blaster_p2p_private_key.scaling.m6=d0007fe900755a81635d0203831fe551175896f510f0dc2f8639bac840c4a275731444f003ecfaeed8c0fb172124bb33c7c559a84accd04b2ab2d4ef5ec7a307
tx_blaster_p2p_peer_id.scaling.m6=12D3KooWHZayp2ZRQyp4SLWr3mwnCkmqyo1HdcEYnFMZdmkHufav
tx_blaster_p2p_private_key.testing.t1=c46672a8343179958b9bc76a0a4079e5ffbfc64aa89316d944b2316bd2e65582171333b40da75e31d23d76c231d67762a9031dcb0cbe725e2114599900b7b125
tx_blaster_p2p_peer_id.testing.t1=12D3KooWBNSXb2x1tUjpofMXckHwmATVGD9kYRT5reBCJEnxXVUQ
tx_blaster_p2p_private_key.testing.t2=74473a119f9adc5b49c0ccd9974c687974ab0ecd0f9330f4d14b3f16fb8c7be71c7d662fef5bc33de42257940a0f79f276e03e06a6f584b178b82d700f49e15e
tx_blaster_p2p_peer_id.testing.t2=12D3KooWBjaVFuwk7S2KHKjnoHNembb6DQDkrumoG24idHKXi7Jd
tx_blaster_p2p_private_key.testing.t3=f0728085429c185ce0b4bcbe48f0b912f5f87464e2ac15a5358900d3e14b5486bf3f9463df2abea9c198d3376b1066be16738f8cd8447fd303802cf82531c6fe
tx_blaster_p2p_peer_id.testing.t3=12D3KooWNgvGZztjDqJQmCTH5fSap2vpfm6XKgWTg1sdyaVWm1RX

# p2p_static_peers is optional, the node will use the bootstrap addresses to find peers regardless
tx_blaster_p2p_static_peers=



# CGO Signer and Verifier Configuration
# ----------------------------------------
use_cgo_signer=true
use_cgo_signer.scaling=true
use_cgo_signer.testing=true

use_cgo_verifier=true
use_cgo_verifier.scaling=true
use_cgo_verifier.testing=true


# IPV6 Addresses
# ----------------------------------------
#ipv6_addresses=ff02::1234


# Feature Switches
feature_libP2P=true

feature_bootstrap=false

tx_blaster_profilerAddr=:${PROFILE_PORT_TXBLASTER}
tx_blaster_profilerAddr.dev=localhost:${PROFILE_PORT_TXBLASTER}

tx_blaster_staggerWorkersTimeMs=20

# time to wait in ms between sending transactions
distributer_wait_time=10

# distributor config
distributor_backoff_duration=1s
distributor_backoff_duration.scaling.m1.coinbase=10s
distributor_backoff_duration.scaling.m2.coinbase=10s
distributor_backoff_duration.scaling.m3.coinbase=10s
distributor_backoff_duration.scaling.m4.coinbase=10s
distributor_backoff_duration.scaling.m5.coinbase=10s
distributor_backoff_duration.scaling.m6.coinbase=10s
distributor_backoff_duration.testing.t1.coinbase=10s
distributor_backoff_duration.testing.t2.coinbase=10s
distributor_backoff_duration.testing.t3.coinbase=10s

distributor_max_retries=3
distributor_failure_tolerance=0


# E2E test configuration
test_run_mode=dev
test_run_mode.docker.ci=ci
min_block_height_for_e2e=200

coinbase_should_wait=true
coinbase_should_wait.dev.simon=false
coinbase_should_wait.docker=false
coinbase_should_wait.docker.host=false

coinbase_wait_until_block=1000
coinbase_wait_until_block.dev=200
coinbase_wait_until_block.docker=300
coinbase_wait_until_block.docker.host=3000

# rpc
rpc_max_clients=3
rpc_listener_url=:9292
rpc_listener_url.docker.host.ubsv1=:19292
rpc_listener_url.docker.host.ubsv2=:29292
rpc_listener_url.docker.host.ubsv3=:39292
rpc_user=bitcoin
rpc_pass=bitcoin

double_spend_window_millis=0

# policy settings 

# use these if you do not want unbounded scaling
excessiveblocksize=2000000000
excessiveblocksize.docker.ci.ubsv2.tc2=1000
blockmaxsize=512000000

maxtxsizepolicy=100000000
maxtxsigopscountspolicy=4294967295
minminingtxfee=1e-8
